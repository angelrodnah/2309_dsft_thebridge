{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install keras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miguel Angel\\AppData\\Local\\Temp\\ipykernel_9260\\3096108358.py:3: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5019607843137255"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "255/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13066062"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "# Capa entrada\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 300,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 100,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Capa salida\n",
    "model.add(keras.layers.Dense(units = 10,\n",
    "                            activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units = 300, activation='relu'),\n",
    "    keras.layers.Dense(units = 100, activation='relu'),\n",
    "    keras.layers.Dense(units = 10, activation='softmax')\n",
    "]\n",
    "\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.layers.reshaping.flatten.Flatten object at 0x000001FD6CB415D0>\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01131682,  0.05714665,  0.06924653, ...,  0.03929841,\n",
       "         0.02207857, -0.04415067],\n",
       "       [ 0.01748335,  0.00034158, -0.05891502, ..., -0.04592942,\n",
       "        -0.04526225, -0.02985714],\n",
       "       [ 0.04106613, -0.03677336, -0.04301096, ...,  0.04660722,\n",
       "         0.01173171, -0.05365624],\n",
       "       ...,\n",
       "       [ 0.06229287, -0.0685567 ,  0.03909349, ...,  0.01762585,\n",
       "         0.00196885, -0.06489025],\n",
       "       [ 0.03405543,  0.00349727,  0.04955422, ..., -0.01371665,\n",
       "        -0.00962634,  0.05403589],\n",
       "       [ 0.01194921, -0.01091875, -0.02364607, ...,  0.07317856,\n",
       "        -0.03126809, -0.01602794]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300*784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biases)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.SGD(),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n",
    "model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266610 (1.02 MB)\n",
      "Trainable params: 266610 (1.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784 * 300 + 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235500\n"
     ]
    }
   ],
   "source": [
    "# 1º neurona de la 1º hidden layer\n",
    "# y = a + w1*x1 + w2*x2 + .... wn*xn\n",
    "# a es el intercepto llamado bias\n",
    "# wn es cada uno de los pesos que va a ir actualizando con el backpropagation\n",
    "# n es 784\n",
    "# En la 1º hidden layer tenemos 784 pesos por cada neurona, al tener 300, tenemos un total de:\n",
    "print(784*300 + 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300 * 784 + 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30100"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300 * 100 + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1010"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * 10 + 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390.625"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50000/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "391/391 [==============================] - 3s 5ms/step - loss: 1.2692 - accuracy: 0.7079 - val_loss: 0.6047 - val_accuracy: 0.8679\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.5173 - accuracy: 0.8702 - val_loss: 0.3978 - val_accuracy: 0.8961\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3987 - accuracy: 0.8922 - val_loss: 0.3369 - val_accuracy: 0.9077\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3493 - accuracy: 0.9040 - val_loss: 0.3017 - val_accuracy: 0.9167\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.3195 - accuracy: 0.9107 - val_loss: 0.2817 - val_accuracy: 0.9227\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.2979 - accuracy: 0.9162 - val_loss: 0.2657 - val_accuracy: 0.9259\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.2809 - accuracy: 0.9214 - val_loss: 0.2513 - val_accuracy: 0.9299\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.2667 - accuracy: 0.9252 - val_loss: 0.2418 - val_accuracy: 0.9322\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.2541 - accuracy: 0.9282 - val_loss: 0.2321 - val_accuracy: 0.9350\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.2433 - accuracy: 0.9314 - val_loss: 0.2215 - val_accuracy: 0.9371\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.2332 - accuracy: 0.9339 - val_loss: 0.2151 - val_accuracy: 0.9387\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2243 - accuracy: 0.9368 - val_loss: 0.2066 - val_accuracy: 0.9419\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.2165 - accuracy: 0.9384 - val_loss: 0.2012 - val_accuracy: 0.9428\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2089 - accuracy: 0.9408 - val_loss: 0.1935 - val_accuracy: 0.9459\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.2017 - accuracy: 0.9422 - val_loss: 0.1885 - val_accuracy: 0.9464\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1952 - accuracy: 0.9442 - val_loss: 0.1834 - val_accuracy: 0.9478\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1889 - accuracy: 0.9461 - val_loss: 0.1808 - val_accuracy: 0.9503\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1830 - accuracy: 0.9476 - val_loss: 0.1745 - val_accuracy: 0.9518\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1776 - accuracy: 0.9489 - val_loss: 0.1697 - val_accuracy: 0.9533\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1723 - accuracy: 0.9505 - val_loss: 0.1655 - val_accuracy: 0.9546\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1674 - accuracy: 0.9516 - val_loss: 0.1621 - val_accuracy: 0.9551\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1625 - accuracy: 0.9532 - val_loss: 0.1597 - val_accuracy: 0.9556\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 0.1581 - accuracy: 0.9547 - val_loss: 0.1554 - val_accuracy: 0.9564\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1539 - accuracy: 0.9558 - val_loss: 0.1522 - val_accuracy: 0.9570\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1498 - accuracy: 0.9578 - val_loss: 0.1490 - val_accuracy: 0.9595\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1460 - accuracy: 0.9580 - val_loss: 0.1461 - val_accuracy: 0.9602\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1423 - accuracy: 0.9595 - val_loss: 0.1435 - val_accuracy: 0.9607\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.1386 - accuracy: 0.9602 - val_loss: 0.1412 - val_accuracy: 0.9617\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.1350 - accuracy: 0.9620 - val_loss: 0.1383 - val_accuracy: 0.9624\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1320 - accuracy: 0.9628 - val_loss: 0.1359 - val_accuracy: 0.9616\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.1289 - accuracy: 0.9636 - val_loss: 0.1330 - val_accuracy: 0.9630\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1259 - accuracy: 0.9647 - val_loss: 0.1318 - val_accuracy: 0.9630\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.1229 - accuracy: 0.9657 - val_loss: 0.1296 - val_accuracy: 0.9641\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1200 - accuracy: 0.9667 - val_loss: 0.1273 - val_accuracy: 0.9650\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1174 - accuracy: 0.9675 - val_loss: 0.1258 - val_accuracy: 0.9653\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1149 - accuracy: 0.9680 - val_loss: 0.1235 - val_accuracy: 0.9653\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1123 - accuracy: 0.9692 - val_loss: 0.1222 - val_accuracy: 0.9657\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1097 - accuracy: 0.9698 - val_loss: 0.1202 - val_accuracy: 0.9664\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1075 - accuracy: 0.9706 - val_loss: 0.1198 - val_accuracy: 0.9666\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1051 - accuracy: 0.9710 - val_loss: 0.1173 - val_accuracy: 0.9670\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1031 - accuracy: 0.9716 - val_loss: 0.1158 - val_accuracy: 0.9681\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1010 - accuracy: 0.9725 - val_loss: 0.1142 - val_accuracy: 0.9681\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0990 - accuracy: 0.9733 - val_loss: 0.1132 - val_accuracy: 0.9682\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0969 - accuracy: 0.9733 - val_loss: 0.1126 - val_accuracy: 0.9689\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0952 - accuracy: 0.9741 - val_loss: 0.1107 - val_accuracy: 0.9684\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0932 - accuracy: 0.9746 - val_loss: 0.1101 - val_accuracy: 0.9691\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0915 - accuracy: 0.9755 - val_loss: 0.1081 - val_accuracy: 0.9699\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0895 - accuracy: 0.9761 - val_loss: 0.1084 - val_accuracy: 0.9694\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0879 - accuracy: 0.9763 - val_loss: 0.1058 - val_accuracy: 0.9699\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0863 - accuracy: 0.9770 - val_loss: 0.1058 - val_accuracy: 0.9703\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 50,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0859 - accuracy: 0.9763 - val_loss: 0.1035 - val_accuracy: 0.9710\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0826 - accuracy: 0.9776 - val_loss: 0.1047 - val_accuracy: 0.9696\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0798 - accuracy: 0.9782 - val_loss: 0.0998 - val_accuracy: 0.9715\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0770 - accuracy: 0.9793 - val_loss: 0.0991 - val_accuracy: 0.9722\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0741 - accuracy: 0.9803 - val_loss: 0.1005 - val_accuracy: 0.9706\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0718 - accuracy: 0.9806 - val_loss: 0.0964 - val_accuracy: 0.9733\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0693 - accuracy: 0.9813 - val_loss: 0.0933 - val_accuracy: 0.9718\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0668 - accuracy: 0.9820 - val_loss: 0.0929 - val_accuracy: 0.9735\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0646 - accuracy: 0.9831 - val_loss: 0.0942 - val_accuracy: 0.9744\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0625 - accuracy: 0.9834 - val_loss: 0.0967 - val_accuracy: 0.9720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1fd6ceb3390>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 64,\n",
    "    epochs = 10,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [1.2692146301269531, 0.5173273086547852, 0.3986569941043854, 0.3493448793888092, 0.31946611404418945, 0.29791459441185, 0.28087928891181946, 0.2666637599468231, 0.25413376092910767, 0.24327042698860168, 0.23324929177761078, 0.2243104875087738, 0.21652908623218536, 0.20891354978084564, 0.20168767869472504, 0.19516749680042267, 0.1888769268989563, 0.18296976387500763, 0.17755240201950073, 0.17233291268348694, 0.16739892959594727, 0.1625271439552307, 0.15809795260429382, 0.15387719869613647, 0.1497545838356018, 0.14598119258880615, 0.14227627217769623, 0.13860778510570526, 0.13502204418182373, 0.13196152448654175, 0.12894847989082336, 0.12586113810539246, 0.1229320764541626, 0.12003398686647415, 0.11744286864995956, 0.11485273391008377, 0.11233208328485489, 0.10972709953784943, 0.1075049489736557, 0.10512509942054749, 0.10310594737529755, 0.10098769515752792, 0.0990135669708252, 0.09692976623773575, 0.09515032172203064, 0.09320750087499619, 0.09148123860359192, 0.08951173722743988, 0.08793856203556061, 0.0863042026758194], 'accuracy': [0.7079200148582458, 0.870199978351593, 0.8922200202941895, 0.9040200114250183, 0.9106600284576416, 0.9162399768829346, 0.9213600158691406, 0.9252399802207947, 0.9282000064849854, 0.9313799738883972, 0.9339200258255005, 0.9368399977684021, 0.9384400248527527, 0.9408199787139893, 0.9422399997711182, 0.9442399740219116, 0.9460800290107727, 0.9476400017738342, 0.9488800168037415, 0.9505400061607361, 0.9515799880027771, 0.9531999826431274, 0.9546599984169006, 0.955780029296875, 0.9577800035476685, 0.9580399990081787, 0.9595000147819519, 0.9602400064468384, 0.9619600176811218, 0.9628199934959412, 0.9636399745941162, 0.964680016040802, 0.965719997882843, 0.9666799902915955, 0.9675400257110596, 0.9680399894714355, 0.9692400097846985, 0.9697800278663635, 0.970579981803894, 0.9709600210189819, 0.9716399908065796, 0.972540020942688, 0.9732999801635742, 0.9732800126075745, 0.9740999937057495, 0.9746000170707703, 0.9754800200462341, 0.9760800004005432, 0.9762799739837646, 0.9769799709320068], 'val_loss': [0.6046667695045471, 0.3977721929550171, 0.33686214685440063, 0.30173259973526, 0.2817268669605255, 0.26573431491851807, 0.25127723813056946, 0.2417575716972351, 0.23211221396923065, 0.22153356671333313, 0.2151268869638443, 0.20657838881015778, 0.2012065052986145, 0.1935185045003891, 0.18853722512722015, 0.1833936870098114, 0.18078336119651794, 0.17447492480278015, 0.16970477998256683, 0.1655213087797165, 0.16209934651851654, 0.1596890687942505, 0.15542322397232056, 0.15217027068138123, 0.14896909892559052, 0.14607615768909454, 0.14350871741771698, 0.1411668211221695, 0.1382894217967987, 0.13587266206741333, 0.13304859399795532, 0.13176089525222778, 0.12960447371006012, 0.12726488709449768, 0.12584500014781952, 0.12350529432296753, 0.12222152203321457, 0.12018271535634995, 0.1198335662484169, 0.11729073524475098, 0.11579208821058273, 0.11418618261814117, 0.1132102906703949, 0.11258304119110107, 0.11065029352903366, 0.1101050153374672, 0.10810396820306778, 0.10837043821811676, 0.10578298568725586, 0.10577359795570374], 'val_accuracy': [0.867900013923645, 0.8960999846458435, 0.9077000021934509, 0.916700005531311, 0.9226999878883362, 0.9258999824523926, 0.9298999905586243, 0.932200014591217, 0.9350000023841858, 0.9370999932289124, 0.9387000203132629, 0.9419000148773193, 0.942799985408783, 0.945900022983551, 0.946399986743927, 0.9477999806404114, 0.9502999782562256, 0.9517999887466431, 0.9532999992370605, 0.9545999765396118, 0.9550999999046326, 0.9556000232696533, 0.9563999772071838, 0.9570000171661377, 0.9595000147819519, 0.9602000117301941, 0.9606999754905701, 0.9617000222206116, 0.9624000191688538, 0.9616000056266785, 0.9629999995231628, 0.9629999995231628, 0.9641000032424927, 0.9649999737739563, 0.9653000235557556, 0.9653000235557556, 0.9656999707221985, 0.9664000272750854, 0.9666000008583069, 0.9670000076293945, 0.9681000113487244, 0.9681000113487244, 0.9682000279426575, 0.9689000248908997, 0.9684000015258789, 0.9690999984741211, 0.9699000120162964, 0.9693999886512756, 0.9699000120162964, 0.970300018787384]}\n"
     ]
    }
   ],
   "source": [
    "# print(history.params)\n",
    "# print(history.epoch)\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.2692146301269531,\n",
       "  0.5173273086547852,\n",
       "  0.3986569941043854,\n",
       "  0.3493448793888092,\n",
       "  0.31946611404418945,\n",
       "  0.29791459441185,\n",
       "  0.28087928891181946,\n",
       "  0.2666637599468231,\n",
       "  0.25413376092910767,\n",
       "  0.24327042698860168,\n",
       "  0.23324929177761078,\n",
       "  0.2243104875087738,\n",
       "  0.21652908623218536,\n",
       "  0.20891354978084564,\n",
       "  0.20168767869472504,\n",
       "  0.19516749680042267,\n",
       "  0.1888769268989563,\n",
       "  0.18296976387500763,\n",
       "  0.17755240201950073,\n",
       "  0.17233291268348694,\n",
       "  0.16739892959594727,\n",
       "  0.1625271439552307,\n",
       "  0.15809795260429382,\n",
       "  0.15387719869613647,\n",
       "  0.1497545838356018,\n",
       "  0.14598119258880615,\n",
       "  0.14227627217769623,\n",
       "  0.13860778510570526,\n",
       "  0.13502204418182373,\n",
       "  0.13196152448654175,\n",
       "  0.12894847989082336,\n",
       "  0.12586113810539246,\n",
       "  0.1229320764541626,\n",
       "  0.12003398686647415,\n",
       "  0.11744286864995956,\n",
       "  0.11485273391008377,\n",
       "  0.11233208328485489,\n",
       "  0.10972709953784943,\n",
       "  0.1075049489736557,\n",
       "  0.10512509942054749,\n",
       "  0.10310594737529755,\n",
       "  0.10098769515752792,\n",
       "  0.0990135669708252,\n",
       "  0.09692976623773575,\n",
       "  0.09515032172203064,\n",
       "  0.09320750087499619,\n",
       "  0.09148123860359192,\n",
       "  0.08951173722743988,\n",
       "  0.08793856203556061,\n",
       "  0.0863042026758194],\n",
       " 'accuracy': [0.7079200148582458,\n",
       "  0.870199978351593,\n",
       "  0.8922200202941895,\n",
       "  0.9040200114250183,\n",
       "  0.9106600284576416,\n",
       "  0.9162399768829346,\n",
       "  0.9213600158691406,\n",
       "  0.9252399802207947,\n",
       "  0.9282000064849854,\n",
       "  0.9313799738883972,\n",
       "  0.9339200258255005,\n",
       "  0.9368399977684021,\n",
       "  0.9384400248527527,\n",
       "  0.9408199787139893,\n",
       "  0.9422399997711182,\n",
       "  0.9442399740219116,\n",
       "  0.9460800290107727,\n",
       "  0.9476400017738342,\n",
       "  0.9488800168037415,\n",
       "  0.9505400061607361,\n",
       "  0.9515799880027771,\n",
       "  0.9531999826431274,\n",
       "  0.9546599984169006,\n",
       "  0.955780029296875,\n",
       "  0.9577800035476685,\n",
       "  0.9580399990081787,\n",
       "  0.9595000147819519,\n",
       "  0.9602400064468384,\n",
       "  0.9619600176811218,\n",
       "  0.9628199934959412,\n",
       "  0.9636399745941162,\n",
       "  0.964680016040802,\n",
       "  0.965719997882843,\n",
       "  0.9666799902915955,\n",
       "  0.9675400257110596,\n",
       "  0.9680399894714355,\n",
       "  0.9692400097846985,\n",
       "  0.9697800278663635,\n",
       "  0.970579981803894,\n",
       "  0.9709600210189819,\n",
       "  0.9716399908065796,\n",
       "  0.972540020942688,\n",
       "  0.9732999801635742,\n",
       "  0.9732800126075745,\n",
       "  0.9740999937057495,\n",
       "  0.9746000170707703,\n",
       "  0.9754800200462341,\n",
       "  0.9760800004005432,\n",
       "  0.9762799739837646,\n",
       "  0.9769799709320068],\n",
       " 'val_loss': [0.6046667695045471,\n",
       "  0.3977721929550171,\n",
       "  0.33686214685440063,\n",
       "  0.30173259973526,\n",
       "  0.2817268669605255,\n",
       "  0.26573431491851807,\n",
       "  0.25127723813056946,\n",
       "  0.2417575716972351,\n",
       "  0.23211221396923065,\n",
       "  0.22153356671333313,\n",
       "  0.2151268869638443,\n",
       "  0.20657838881015778,\n",
       "  0.2012065052986145,\n",
       "  0.1935185045003891,\n",
       "  0.18853722512722015,\n",
       "  0.1833936870098114,\n",
       "  0.18078336119651794,\n",
       "  0.17447492480278015,\n",
       "  0.16970477998256683,\n",
       "  0.1655213087797165,\n",
       "  0.16209934651851654,\n",
       "  0.1596890687942505,\n",
       "  0.15542322397232056,\n",
       "  0.15217027068138123,\n",
       "  0.14896909892559052,\n",
       "  0.14607615768909454,\n",
       "  0.14350871741771698,\n",
       "  0.1411668211221695,\n",
       "  0.1382894217967987,\n",
       "  0.13587266206741333,\n",
       "  0.13304859399795532,\n",
       "  0.13176089525222778,\n",
       "  0.12960447371006012,\n",
       "  0.12726488709449768,\n",
       "  0.12584500014781952,\n",
       "  0.12350529432296753,\n",
       "  0.12222152203321457,\n",
       "  0.12018271535634995,\n",
       "  0.1198335662484169,\n",
       "  0.11729073524475098,\n",
       "  0.11579208821058273,\n",
       "  0.11418618261814117,\n",
       "  0.1132102906703949,\n",
       "  0.11258304119110107,\n",
       "  0.11065029352903366,\n",
       "  0.1101050153374672,\n",
       "  0.10810396820306778,\n",
       "  0.10837043821811676,\n",
       "  0.10578298568725586,\n",
       "  0.10577359795570374],\n",
       " 'val_accuracy': [0.867900013923645,\n",
       "  0.8960999846458435,\n",
       "  0.9077000021934509,\n",
       "  0.916700005531311,\n",
       "  0.9226999878883362,\n",
       "  0.9258999824523926,\n",
       "  0.9298999905586243,\n",
       "  0.932200014591217,\n",
       "  0.9350000023841858,\n",
       "  0.9370999932289124,\n",
       "  0.9387000203132629,\n",
       "  0.9419000148773193,\n",
       "  0.942799985408783,\n",
       "  0.945900022983551,\n",
       "  0.946399986743927,\n",
       "  0.9477999806404114,\n",
       "  0.9502999782562256,\n",
       "  0.9517999887466431,\n",
       "  0.9532999992370605,\n",
       "  0.9545999765396118,\n",
       "  0.9550999999046326,\n",
       "  0.9556000232696533,\n",
       "  0.9563999772071838,\n",
       "  0.9570000171661377,\n",
       "  0.9595000147819519,\n",
       "  0.9602000117301941,\n",
       "  0.9606999754905701,\n",
       "  0.9617000222206116,\n",
       "  0.9624000191688538,\n",
       "  0.9616000056266785,\n",
       "  0.9629999995231628,\n",
       "  0.9629999995231628,\n",
       "  0.9641000032424927,\n",
       "  0.9649999737739563,\n",
       "  0.9653000235557556,\n",
       "  0.9653000235557556,\n",
       "  0.9656999707221985,\n",
       "  0.9664000272750854,\n",
       "  0.9666000008583069,\n",
       "  0.9670000076293945,\n",
       "  0.9681000113487244,\n",
       "  0.9681000113487244,\n",
       "  0.9682000279426575,\n",
       "  0.9689000248908997,\n",
       "  0.9684000015258789,\n",
       "  0.9690999984741211,\n",
       "  0.9699000120162964,\n",
       "  0.9693999886512756,\n",
       "  0.9699000120162964,\n",
       "  0.970300018787384]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.269215</td>\n",
       "      <td>0.70792</td>\n",
       "      <td>0.604667</td>\n",
       "      <td>0.8679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.517327</td>\n",
       "      <td>0.87020</td>\n",
       "      <td>0.397772</td>\n",
       "      <td>0.8961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.398657</td>\n",
       "      <td>0.89222</td>\n",
       "      <td>0.336862</td>\n",
       "      <td>0.9077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.349345</td>\n",
       "      <td>0.90402</td>\n",
       "      <td>0.301733</td>\n",
       "      <td>0.9167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.319466</td>\n",
       "      <td>0.91066</td>\n",
       "      <td>0.281727</td>\n",
       "      <td>0.9227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.297915</td>\n",
       "      <td>0.91624</td>\n",
       "      <td>0.265734</td>\n",
       "      <td>0.9259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.280879</td>\n",
       "      <td>0.92136</td>\n",
       "      <td>0.251277</td>\n",
       "      <td>0.9299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.266664</td>\n",
       "      <td>0.92524</td>\n",
       "      <td>0.241758</td>\n",
       "      <td>0.9322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.254134</td>\n",
       "      <td>0.92820</td>\n",
       "      <td>0.232112</td>\n",
       "      <td>0.9350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.243270</td>\n",
       "      <td>0.93138</td>\n",
       "      <td>0.221534</td>\n",
       "      <td>0.9371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.233249</td>\n",
       "      <td>0.93392</td>\n",
       "      <td>0.215127</td>\n",
       "      <td>0.9387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.224310</td>\n",
       "      <td>0.93684</td>\n",
       "      <td>0.206578</td>\n",
       "      <td>0.9419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.216529</td>\n",
       "      <td>0.93844</td>\n",
       "      <td>0.201207</td>\n",
       "      <td>0.9428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.208914</td>\n",
       "      <td>0.94082</td>\n",
       "      <td>0.193519</td>\n",
       "      <td>0.9459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.201688</td>\n",
       "      <td>0.94224</td>\n",
       "      <td>0.188537</td>\n",
       "      <td>0.9464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.195167</td>\n",
       "      <td>0.94424</td>\n",
       "      <td>0.183394</td>\n",
       "      <td>0.9478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.188877</td>\n",
       "      <td>0.94608</td>\n",
       "      <td>0.180783</td>\n",
       "      <td>0.9503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.182970</td>\n",
       "      <td>0.94764</td>\n",
       "      <td>0.174475</td>\n",
       "      <td>0.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.177552</td>\n",
       "      <td>0.94888</td>\n",
       "      <td>0.169705</td>\n",
       "      <td>0.9533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.172333</td>\n",
       "      <td>0.95054</td>\n",
       "      <td>0.165521</td>\n",
       "      <td>0.9546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.167399</td>\n",
       "      <td>0.95158</td>\n",
       "      <td>0.162099</td>\n",
       "      <td>0.9551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.162527</td>\n",
       "      <td>0.95320</td>\n",
       "      <td>0.159689</td>\n",
       "      <td>0.9556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.158098</td>\n",
       "      <td>0.95466</td>\n",
       "      <td>0.155423</td>\n",
       "      <td>0.9564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.153877</td>\n",
       "      <td>0.95578</td>\n",
       "      <td>0.152170</td>\n",
       "      <td>0.9570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.149755</td>\n",
       "      <td>0.95778</td>\n",
       "      <td>0.148969</td>\n",
       "      <td>0.9595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.145981</td>\n",
       "      <td>0.95804</td>\n",
       "      <td>0.146076</td>\n",
       "      <td>0.9602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.142276</td>\n",
       "      <td>0.95950</td>\n",
       "      <td>0.143509</td>\n",
       "      <td>0.9607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.138608</td>\n",
       "      <td>0.96024</td>\n",
       "      <td>0.141167</td>\n",
       "      <td>0.9617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.135022</td>\n",
       "      <td>0.96196</td>\n",
       "      <td>0.138289</td>\n",
       "      <td>0.9624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.131962</td>\n",
       "      <td>0.96282</td>\n",
       "      <td>0.135873</td>\n",
       "      <td>0.9616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.128948</td>\n",
       "      <td>0.96364</td>\n",
       "      <td>0.133049</td>\n",
       "      <td>0.9630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.125861</td>\n",
       "      <td>0.96468</td>\n",
       "      <td>0.131761</td>\n",
       "      <td>0.9630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.122932</td>\n",
       "      <td>0.96572</td>\n",
       "      <td>0.129604</td>\n",
       "      <td>0.9641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.120034</td>\n",
       "      <td>0.96668</td>\n",
       "      <td>0.127265</td>\n",
       "      <td>0.9650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.117443</td>\n",
       "      <td>0.96754</td>\n",
       "      <td>0.125845</td>\n",
       "      <td>0.9653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.114853</td>\n",
       "      <td>0.96804</td>\n",
       "      <td>0.123505</td>\n",
       "      <td>0.9653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.112332</td>\n",
       "      <td>0.96924</td>\n",
       "      <td>0.122222</td>\n",
       "      <td>0.9657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.109727</td>\n",
       "      <td>0.96978</td>\n",
       "      <td>0.120183</td>\n",
       "      <td>0.9664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.107505</td>\n",
       "      <td>0.97058</td>\n",
       "      <td>0.119834</td>\n",
       "      <td>0.9666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.105125</td>\n",
       "      <td>0.97096</td>\n",
       "      <td>0.117291</td>\n",
       "      <td>0.9670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.103106</td>\n",
       "      <td>0.97164</td>\n",
       "      <td>0.115792</td>\n",
       "      <td>0.9681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.100988</td>\n",
       "      <td>0.97254</td>\n",
       "      <td>0.114186</td>\n",
       "      <td>0.9681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.099014</td>\n",
       "      <td>0.97330</td>\n",
       "      <td>0.113210</td>\n",
       "      <td>0.9682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.096930</td>\n",
       "      <td>0.97328</td>\n",
       "      <td>0.112583</td>\n",
       "      <td>0.9689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.095150</td>\n",
       "      <td>0.97410</td>\n",
       "      <td>0.110650</td>\n",
       "      <td>0.9684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.093208</td>\n",
       "      <td>0.97460</td>\n",
       "      <td>0.110105</td>\n",
       "      <td>0.9691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.091481</td>\n",
       "      <td>0.97548</td>\n",
       "      <td>0.108104</td>\n",
       "      <td>0.9699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.089512</td>\n",
       "      <td>0.97608</td>\n",
       "      <td>0.108370</td>\n",
       "      <td>0.9694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.087939</td>\n",
       "      <td>0.97628</td>\n",
       "      <td>0.105783</td>\n",
       "      <td>0.9699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.086304</td>\n",
       "      <td>0.97698</td>\n",
       "      <td>0.105774</td>\n",
       "      <td>0.9703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "0   1.269215   0.70792  0.604667        0.8679\n",
       "1   0.517327   0.87020  0.397772        0.8961\n",
       "2   0.398657   0.89222  0.336862        0.9077\n",
       "3   0.349345   0.90402  0.301733        0.9167\n",
       "4   0.319466   0.91066  0.281727        0.9227\n",
       "5   0.297915   0.91624  0.265734        0.9259\n",
       "6   0.280879   0.92136  0.251277        0.9299\n",
       "7   0.266664   0.92524  0.241758        0.9322\n",
       "8   0.254134   0.92820  0.232112        0.9350\n",
       "9   0.243270   0.93138  0.221534        0.9371\n",
       "10  0.233249   0.93392  0.215127        0.9387\n",
       "11  0.224310   0.93684  0.206578        0.9419\n",
       "12  0.216529   0.93844  0.201207        0.9428\n",
       "13  0.208914   0.94082  0.193519        0.9459\n",
       "14  0.201688   0.94224  0.188537        0.9464\n",
       "15  0.195167   0.94424  0.183394        0.9478\n",
       "16  0.188877   0.94608  0.180783        0.9503\n",
       "17  0.182970   0.94764  0.174475        0.9518\n",
       "18  0.177552   0.94888  0.169705        0.9533\n",
       "19  0.172333   0.95054  0.165521        0.9546\n",
       "20  0.167399   0.95158  0.162099        0.9551\n",
       "21  0.162527   0.95320  0.159689        0.9556\n",
       "22  0.158098   0.95466  0.155423        0.9564\n",
       "23  0.153877   0.95578  0.152170        0.9570\n",
       "24  0.149755   0.95778  0.148969        0.9595\n",
       "25  0.145981   0.95804  0.146076        0.9602\n",
       "26  0.142276   0.95950  0.143509        0.9607\n",
       "27  0.138608   0.96024  0.141167        0.9617\n",
       "28  0.135022   0.96196  0.138289        0.9624\n",
       "29  0.131962   0.96282  0.135873        0.9616\n",
       "30  0.128948   0.96364  0.133049        0.9630\n",
       "31  0.125861   0.96468  0.131761        0.9630\n",
       "32  0.122932   0.96572  0.129604        0.9641\n",
       "33  0.120034   0.96668  0.127265        0.9650\n",
       "34  0.117443   0.96754  0.125845        0.9653\n",
       "35  0.114853   0.96804  0.123505        0.9653\n",
       "36  0.112332   0.96924  0.122222        0.9657\n",
       "37  0.109727   0.96978  0.120183        0.9664\n",
       "38  0.107505   0.97058  0.119834        0.9666\n",
       "39  0.105125   0.97096  0.117291        0.9670\n",
       "40  0.103106   0.97164  0.115792        0.9681\n",
       "41  0.100988   0.97254  0.114186        0.9681\n",
       "42  0.099014   0.97330  0.113210        0.9682\n",
       "43  0.096930   0.97328  0.112583        0.9689\n",
       "44  0.095150   0.97410  0.110650        0.9684\n",
       "45  0.093208   0.97460  0.110105        0.9691\n",
       "46  0.091481   0.97548  0.108104        0.9699\n",
       "47  0.089512   0.97608  0.108370        0.9694\n",
       "48  0.087939   0.97628  0.105783        0.9699\n",
       "49  0.086304   0.97698  0.105774        0.9703"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAp8AAAGyCAYAAACiMq99AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB9VUlEQVR4nO3deXgU9eHH8ffsvZv7gARCwg0ip5ziraAoSj1bq1bRVnuJVqlVaVVqbUVrtdpqf1ZbtbZe9baCKCJ4ICiCoCggdzhykfvae35/bLIQSGA3kITEz+t55pnZ2Zmd72YS+fi9xjBN00REREREpB1YOroAIiIiIvLtofApIiIiIu1G4VNERERE2o3Cp4iIiIi0G4VPEREREWk3Cp8iIiIi0m4UPkVERESk3Sh8ioiIiEi7UfgUERERkXaj8CkiIiIi7Sbu8PnBBx8wbdo0evbsiWEYvPbaawc9Z/HixYwePRqn08mAAQN46qmnWlFUEREREens4g6ftbW1jBw5kkceeSSm47ds2cLZZ5/NqaeeyqpVq7jhhhu4+uqrefvtt+MurIiIiIh0boZpmmarTzYMXn31Vc4777wWj7nllluYO3cua9asie77/ve/T0VFBfPnz2/tpUVERESkE7K19QWWLl3K5MmTm+ybMmUKN9xwQ4vn+Hw+fD5f9HU4HKasrIyMjAwMw2irooqIiIhIK5mmSXV1NT179sRiablxvc3DZ2FhIVlZWU32ZWVlUVVVRX19PW63e79z5syZw5133tnWRRMRERGRw2z79u306tWrxffbPHy2xqxZs5g5c2b0dWVlJXl5eWzZsoWkpKQ2v34gEGDRokWceuqp2O12xs9ZRCBk8tb1x5Gd7Grz68vhs++9lM5L97Lr0L3sOnQvu47DcS+rq6vp27fvQbNam4fP7OxsioqKmuwrKioiOTm52VpPAKfTidPp3G9/eno6ycnJbVLOvQUCATweDxkZGdjtdhISk6jyBnElppCRkdjm15fDZ997KZ2X7mXXoXvZdehedh2H4142nnewLpJtPs/nxIkTWbhwYZN9CxYsYOLEiW196cPG7bACUO8PdXBJRERERDq3uMNnTU0Nq1atYtWqVUBkKqVVq1aRn58PRJrMr7jiiujxP/3pT9m8eTM333wz69at429/+xv//e9/ufHGGw/PN2gHbnskfHoDCp8iIiIihyLu8PnZZ59xzDHHcMwxxwAwc+ZMjjnmGO644w4ACgoKokEUoG/fvsydO5cFCxYwcuRI7r//fv7xj38wZcqUw/QV2p6rIXzWqeZTRERE5JDE3efzlFNO4UBTgzb39KJTTjmFzz//PN5LHTE8jc3uqvkUEREROSR6tnsMGvt8qtldRERE5NAckVMtHWka+3xqwJGIiMi3VCgIQS+E/JF10AtB/z779nodCkA40LAONvO68ZgQmOGmC+Y++9hrO7Tn3JD/ANsN61GXweTZHf3Ta0LhMwaNfT7V7C4iIhKDcKghjPn2WjdshwIQ8jUENv9eockfOWbv98Ph5j+/uZl8TBo+x9fwuXuvfXt9/l7rcCgSBMMNgbDxdWMoDAf3vG+2UJYjnbeio0uwH4XPGLgVPkVEpL2Fw02DUWjv7UDzYWq/fQ0BLNxYwxaKfK4Z2hO2zNCe2rdoAAscoDZtz7Yt5GNyVQW2jbc0DZhmF//30mLDtLowcWBaXJjYMQ1nZI0D02LHsNswbHYMmwMat+0OaFgbDmdk22rHNCxgGpghs6Hi08AMm5gmEApjho3IdtiMbBs2MCyYphUMK6ZpAayYWDBp2DYNwIK9+yCan1W94yh8xkDzfIqIdHGmGQlV0SZU3/7NqaF9astC+9SW7Vd75oeAFwK1EKiPLP7G7bqGpWHbX9fw+e1f0xYJNQ1rMxJywiEDM2hE1qG91sF9XocMCEN99NMM2DfqGBaw2MBiBcOG2bDGsDbss0aOMWyREBbdF/m31wyamKFwZGmyHY6EtdCetWGxgM2KYY0s2GwYVhuGzRoJerZICMTWcP3oZ4UinxcM7bMEI+tAANMfwAwEMQMBwoEABAJ7fclAw9IKhtHww28baZdeinv8yW32+a2h8BkDhU8RkXZimg3Brz4S3Br71gXqD7L2NjnHDHjBX0/YW4/prcf0+TB9XsI+L6bPj+lvXAKYoQAEAw3ha08Ii25DpBYp3nxgNg10kdqsffft+exIlz4bZtiOGXZHarjCRNahxnMNzLAFwgYmBjQskVouo+GyRqT8NFynsSxhs6HmzGzyuv2FAX8HXLdtGXZ7ZHE4wGLBDIUgGIwE2IbtZh0oeNpse4K03R5ZWy2RQG21gtW6J3BbrNH13u/Z83Lb5gsfAoXPGKjZXUQ6O9M0IRCI1OAcaPH7MetrMOuqIOSLVEhZTAyriWExsVjCGJYwhhHCMMIYliAGkVo+01dHuLaOcF0d4bp6zPp6wnX1hOu9hL0+wl4/Ya+fkNfPMTW1lL84u2kzb+P2vinPZL/at5Zq5CL7Isc33zFwb9aGxdUmP/P21ZBkDxeLBYvLheFyYbicWFzu6NricmI4XVjcLky7g+0FBeTl5mKxxDiBjmE0LA3bND6O0djrPaPhpQXD4WgIdfY9AW+fJRLMbGBGai8JBffUWoaCEApFai0bt4MhMM09nx0Nji1fY085HPsvdvtBHylpmmbk2vuEUjMYjNTIWq1gtUWa6xvD40E+s7NS+IyBwqeIxMs0TcK1tYRKSwnX1bUQ9JoPgJF/OBua/EJBCIYa/pEKRP7R8nsx/V7wextq83wNNXv+hm0/YX9DkPQHI9uBUJs27UWCT3z/UNay939T7Q1L2zBs1oZgYcNwOLA4HBhOR0MfvL3+4bdEmmqxWCLbFkukZsliidQ4xRsGrLbma6ZskSZnw2qJHGO1RMLGvmHI3tA/cL99tj1lMwwwLBiWhtBmsTQ0Y9P0fdteNWLNrRvKZVgskTAXw3cNBAKsmDePsVOn6tnuB2EYRuR3zWYDp7Oji9OhFD5joHk+Rb4dGmshzEAw0gwbCDTUnkT2NYa/sM9HqLyCUFkpwbJyQrtLCO4uiqzLyghVVBKqqI7UrhzBDIu519JYwxlZR2qlLA1Nv0bTpt+Q2cx4kj1BxbBbsThtWFx2LE4HFpcDi9sZWVwucLsoLi8nKzsn0v/OiAQ/DFvD2hrpI9gYoAwDw+HEcLuwOF171i4nFrcbw+mM1tJZXK7Ia6cTw+ncUzMVa62ciLQ5hc8YuDTPp0irmaaJ6fdHav/q6wnX1+9plvXWRwMf0Saopk1mjbWAQb+P9K/XUrplC5awuX+NYMO5kf0NNYf+PX37woGGbZ8P0+9r2ucvEIg2wx1uhi2MxWZi2TvY7R32LOwfAC1gGCY0rA0LDSGscdvEsDQEMpsNw2HD4mhornPYsTgamgadDizOhvDlaghsnmSMhBRwp2C4U8CZBM4UcCU3bCdHtu0JkRq0A9xXAoGGWlU/ZiCAxeOJhEGr9YA/k0AgwPJ58xiq2jKRbyWFzxi49Wx3+RYxg0HCtbWRpa4uuh1q3Fdb29Cvr2HdZH/DOfX1hOvrMOsiYbPFufrilAmULzgsHxU7ixkNfXsHRKszjNUZxuYMY3WFsTlDWBOd2JI9WFOTsKWmYE3PwJKcDnZPwwjexibQxu2GZd/3HIngSABnw9qRtNfrhsXmjPaX6wiGYYDDgdXhABI6rBwi0vkofMbAo2Z36WTMQIBgeTmh8nJCpQ1Nw2WlkSbh0jJC1dXNBsxwbS2mz9dm5TJsFiwOK4bdgsVuYLFFgh2GGRm8QhiMMAYhDCMEhCOBz6Chto89NX/GnubhxmP21ApG1hYL0YEykfVeTctON4bL0zCQIgHD6QanG8PpwXB5Gl4nYNjdkfBod0XWNhfY3eBOBVdawzoVXCmRJmMRETkg/ZcyBhpwJG3BDIf3amqONDMT2mteOZ832jwdrmsIiXV1mHV10e3oyOLamoaAWUawrIxwZeWhF9Bqweq0YnFasTiMSFi0m5EmZFsYizUYWSwBLBYfFluo4b29jrGZGDYTizWyzziEbnemxU7QsGNLSMeINhHvvTTscyQ2vE6M7HMk7FWT2FCDaPd0aK2hiMi3mcJnDFwOhU85MNPvJ1hSQqComGBxMcHiIoLFxQSKiwk27istjYxkbpzz7TA1RbfIAKvHhs1tweoysTpD2Ox+rHYvVnsoEg4bw6Q9vCc02hvDZSuva3XsCYJ79yHcNyQ2LnY32NyRmkWbO9KcbHfvqWG0ucDmIhg2mTdvHlPVT1BEpFNT+IxBtObT30mf6yotMsNhQmVlBAqLIoFx925Mb2RASuOUNZFBKfu89vkI+yMjnoPFxYTKyg5foayRKVMsdguGwxJ5MIjdxGINYbEEsVj8kbW9aS2jNdr3sGHbET54TaMjaU8/wia1hYkN20l7ag3t7sggFIdnz7bdvacmsXHb2kbBMNzKp4eIiMgRReEzBnvCZwtPJ5AjimmamF4v4dpa/BUVuLZspXr+fMyS3QSLiggUFxEsLIpsl5Ts84i0Q2C1Yk/1YEtxYku0YvOY2F1BbI56bLZqbEYlhhHcM4q5cSSzQcOgFuJrljasTfsbuhvWzuTIuqVl7+ZpTT8jIiLtTOEzBp69mt1N0+yyTxw4UpjhMOHqakKVlZGlomFdWUGospJwZRWh2hrCNbWEa2oiA2VqaiL7ausI19RAaE8XiTyg6EAXNAysqUnY0xKxJdkbphcMY1hCGASxWIIYBDBMPwZ+DNOLxfRiWCK1izZ3CJs7UtsY86+G3dPQFzFhz+jlJq8b+ie69xrQsu/amaR+iyIi0ukofMagsc9n2AR/KIzT1trOcN9e4dpagrt3R5aShvXuEoK7dxMq2U2wopxQRQXhikpC1dWHpz+kYWBxOQg6LCR0S8KeaMXmCWF3eLHZa7AZZdidPmzuUOsHwljs4MkETwYkZETWja/33edO2zPgpdUdKkVERDo3hc8YNDa7A3j9Cp/RxwY2TuVTUUGovDwytU9FRcOTX8oIlpZGA6dZVxf3dQyPB2tKSmRJSsSa4MDqsmBxmFhtocgIa4sXi1mH1azBEqqILNRG+0PGVDHoToPEbEjKgoTuDU3TiXsGx0T7Q+7VJ3LvvpCqfRQREYmZwmcM7FYLNotBMGxSHwiR0obPHz4ShKqq8G/fTmD7DgI7tuPP305gx/ZIjWVFOaGKylb1k7R4PFi7ZWLL7IYtMzOyZGRgS3ZFBsjYvFiNGqxmFZZQGZb6QqjaBVUbwRfD1EF7/zZbHZDQDdOTQXEddOs7HEtyD0jKhsSsPevErMgoaxEREWkXCp8xctutVPuCXWK6pXB9fWSwTWFhNGT6t+dHwub27YRinCPScLuxpqViS03DmpqKNS0tsqSmYk1NwZZkx+Y2sTmC2Ox1WAJlUF0INUVQvQqqi2B3MRTHOJDLkQhJewXIhMyGpVtk8ez1uqE/ZDAQYFnD9DwWTc8jIiLS4RQ+Y+RyRMJn3RE84t00TUIVkal/goWFBIoio7oDxUWRuSYLCwkUF8c0Abk1MxNHr17Y83Jx9MrFnpuLPav7noCZkoIlWAnl26BiW2RdvhUq1kW2N+0EM9agbkQCY3IPSOoJyT332u4ByTmR0OlKPqSfj4iIiHQ8hc8YHWmP2DRNk0B+PvVr1uD96mu8X32F96uvIiO9Y2B4PNizsrDn9oqEy7xcHLm52Hvl4sjthcXjAdOE2hIo/hqK10LZEtiytSFw5kOw/iAXsUT6UCZlNfSpzN6r2bvHnv2J3dtubkgRERE5oih8xqgjJ5o3TZPA9u14v/qqSdgMV1c3e7w1LQ1bdjb27t2xZWdjy+qOPSsbW1YW9uwsbFlZWBITm04ZVV8Oxeug+ENYtBZK1kVCZ11pywUzLJFaydTekNYH0no3bPeG1LxIyNSobhEREdmLwmeMXO34fHfTNPFv3Ej1osXULVtK/ZqvCFdV7Xec4XDgPOooXEOPxj10KK5hw3D07YvF6Wz5w0MBKFkPm76EojWRGs3itVC9q4UTDEjvC92PhowBTUNmSi7YHIflO4uIiMi3g8JnjNxtHD5Nv5+6zz6jetFiahYtIrBjR5P3Dbt9T9AcNgzX0KE4BwzAONAgmvqKSMAs/BIK10DhF5EazZC/+eOTe0H3IQ3L0ZF15qDI4xRFREREDgOFzxi5G/t8+g9f+AyWl1P74YdUL1pE7YcfNemvaTgceI6dQOIpp+AZNSoSNB0HqGWsKYEdy6FgdUPg/CLSL7M5zmTIHg5ZwyDr6EjQ7DY4Mr+liIiISBtS+IxRY83noY5292/dSvXChVQvWkT9ys+bPMnHmpFB4iknk3TqqSRMnIglIaH5DwkFIwFzx/LIsv1TKN/S/LEpeZGgmT2sYT080mSuidFFRESkAyh8xsgdfb57/AOOwnV1VL39DhUvvUT9ihVN3nMOGkTiqaeSdNqpuIYPx7A085zH2t2RgLnjU9i+HHathEAzTwzKHAw5oyF7xJ7A6U6Lu7wiIiIibUXhM0bx9vk0TRPvmjVUvPQyVW++Sbi2NvKGxULCsRNIPG0SiaecgqNXTvMfULoJVj4Na9+Ass37v+9MgV5joNd4yB0HOWPBndqKbyYiIiLSfhQ+Y+SOcZ7PYHk5Vf97k4qXXsL3zTfR/fbcXFIvvJCU88/DnpXV/MkBL6x7E1Y8BVs/bPpe5uBIyOw1HnLHR143V0sqIiIicgRT+IxRdKqlZgYcmeEwdcuWUfHSy1QvWIDZ8Nxzw+EgacoUUi+8EM/4cc03qUNkfs2V/4LVz0Xm24ycDQMmw+jLoe/JqtUUERGRLkHhM0YtNbtXv7eIoj/8gcDOndF9zqOHRGo5zzkHa0oLI8j9dfDVq5HQuf2TPfuTc+CYy+GYH0Bq7mH/HiIiIiIdSeEzRm57pNZy75rPytdfZ9evfwOhEJakJFKmnUPKhRfiHjq05Q8q+ho++yd88V/wNUwcb1hh8FkwejoMmKSnAomIiEiXpfAZI48j8qNqrPkse/ZZin53FwApF1xA9h23Y3G5Wv6AcAg+vB8WzwGzYcR8Wh8YfQWMuizyzHMRERGRLk7hM0Yux54+n7sfe5ySBx4AIO3yy8madWvL/TkBqgvhlWtgyweR14OnwoSfQJ+TNGhIREREvlUUPmPktlvBNDnp/f9SsuItADJ//jMyr7sO40ATtm94F179CdTtBnsCnH0/jLqknUotIiIicmRR+IyR22rw8y9e5ZQtHwPQ/Vc3kfGjH7V8QigA790FSx6KvM4aDt99EjIHtkNpRURERI5MCp8xMINBUv4yh2lbPiaMQc/fzibt+xe3fEL5VnjpR7Dzs8jrcdfAGb8H+wH6hIqIiIh8Cyh8HkTY72fXL3+JbeG7hAwLjx1/OX85UPD86jV443rwVYIrBc59BIZMa7fyioiIiBzJFD4PIFxXR8GNM6n9+GNwOLjrmMv4Omdk8wcH6uHtX8NnT0Re9xoPF/0TUvPar8AiIiIiRziFzxZY6uvZ9dOf4f38cwyPh4Q/PsAn79Zga+7xmiXr4aUfQtEawIATboRTfw1We7uXW0RERORIpvDZjFBZGb0eexzvrl1YkpPJ/fujBAYPg3ffIRg2CYTC2K0NUyRt+RCe/R4E6iChG1zwGPQ/rWO/gIiIiMgRSuFzH4HCQnZc9UNcu3ZhTU8j75//xDVkCL7gnhrP+kBoT/hc+nAkePY5ES78JyRldVDJRURERI58muF8H4GCAoKFBQRSUsh56ilcQ4YA4LBasDRM57n3IzYp/DKyPvU3Cp4iIiIiB6Gaz314jjmGHg8/zEcbNjCkb9/ofsMw8Dhs1PiCe8JnXRlU7YxsZx3gee4iIiIiAqjms1me8eMJpqXtt99lb3jEZuOgo6I1kXVqb3Alt1fxRERERDothc84uB2RH1c0fBY2hM/s4R1UIhEREZHOReEzDu6Gmk+vf5+aT4VPERERkZgofMbBvW+ze+Ngo6xhHVQiERERkc5F4TMOjX0+6/whCAWgZF3kjWyFTxEREZFYKHzGwePYq+Zz9zcQ8oMzOTLgSEREREQOSuEzDu6G8OkNhPYMNsoaCobRgaUSERER6Tw0z2ccolMt+UNQrf6eIiIiIvFSzWccmgw4ik6zpPApIiIiEiuFzzg0CZ+N0yxlaZolERERkVgpfMahccCRtbYYakvAsED3IR1cKhEREZHOQ+EzDq6G8JlW/U1kR8YAcHg6sEQiIiIinYvCZxwam9271TaETw02EhEREYmLwmccGsNnj/oNkR0abCQiIiISF4XPODTO85nj2xTZocFGIiIiInFR+IyDy27FiZ8ewR2RHar5FBEREYmLwmccPA4rA40dWAmDOx2SenR0kUREREQ6FYXPOLjtVoZY8iMvsofrsZoiIiIicVL4jIPLbuVoY1vkRbb6e4qIiIjES+EzDm7HXjWfmmZJREREJG6tCp+PPPIIffr0weVyMWHCBD799NMDHv/ggw8yePBg3G43ubm53HjjjXi93lYVuCO5bZa9aj4VPkVERETiFXf4fOGFF5g5cyazZ89m5cqVjBw5kilTplBcXNzs8c8++yy33nors2fPZu3atfzzn//khRde4Ne//vUhF769JdQXkGzU4TetBNMHdnRxRERERDqduMPnAw88wDXXXMNVV13F0UcfzaOPPorH4+GJJ55o9viPP/6Y448/nksvvZQ+ffpwxhlncMkllxy0tvRI5C5fC8AmM4f6sLWDSyMiIiLS+djiOdjv97NixQpmzZoV3WexWJg8eTJLly5t9pzjjjuO//znP3z66aeMHz+ezZs3M2/ePC6//PIWr+Pz+fD5fNHXVVVVAAQCAQKBQDxFbpXGa+x7LUvRlwB8beaRUufDpfx5xGvpXkrno3vZdehedh26l13H4biXsZ4bV/jcvXs3oVCIrKysJvuzsrJYt25ds+dceuml7N69mxNOOAHTNAkGg/z0pz89YLP7nDlzuPPOO/fb/8477+DxeOIp8iFZsGBBk9fjtiykJ7A23JuKBQvJdLVbUeQQ7XsvpfPSvew6dC+7Dt3LruNQ7mVdXV1Mx8UVPltj8eLF3H333fztb39jwoQJbNy4kV/84hfcdddd3H777c2eM2vWLGbOnBl9XVVVRW5uLmeccQbJycltXWQCgQALFizg9NNPx263R/fb/jYbgK/N3px//IkMykpq87LIoWnpXkrno3vZdehedh26l13H4biXjS3VBxNX+MzMzMRqtVJUVNRkf1FREdnZ2c2ec/vtt3P55Zdz9dVXAzB8+HBqa2v58Y9/zG9+8xsslv27nTqdTpxO53777XZ7u/5yN7merxrKtwKwNpxHwLToD60Tae/fHWk7upddh+5l16F72XUcyr2M9by4Bhw5HA7GjBnDwoULo/vC4TALFy5k4sSJzZ5TV1e3X8C0WiOdJU3TjOfyHavoa8Bkt5FOOcnU+YMdXSIRERGRTifuZveZM2cyffp0xo4dy/jx43nwwQepra3lqquuAuCKK64gJyeHOXPmADBt2jQeeOABjjnmmGiz++233860adOiIbRTaBhstNXWDwBvINSRpRERERHplOIOnxdffDElJSXccccdFBYWMmrUKObPnx8dhJSfn9+kpvO2227DMAxuu+02du7cSbdu3Zg2bRp/+MMfDt+3aA+FawDY7oiEz3p/uCNLIyIiItIptWrA0YwZM5gxY0az7y1evLjpBWw2Zs+ezezZs1tzqSNHUSR8FrgGAFCvmk8RERGRuOnZ7rEIhxv6fEKxJ/JkI4VPERERkfgpfMaifAsEasHmpiqhNwBev8KniIiISLwUPmNRGBlsRPchuJwOAOoUPkVERETi1uaTzHcJjeEzexhuS2SEvprdRUREROKnms9YNAw2Ims4bnskfGqqJREREZH4KXzGomGaJbKH4XY01Hyq2V1EREQkbgqfB1NXBlU7IttZQ3HZ1ewuIiIi0loKnwdT9FVknZoHrpRos7sGHImIiIjET+HzYPbq7wngcajPp4iIiEhrKXweTLS/ZyR8qtldREREpPUUPg+maM80S4AGHImIiIgcAoXPAwkFoHhtZDurIXxqqiURERGRVlP4PJDSjRDygyMJUiOP1XSr2V1ERESk1RQ+D8AobhxsNBQskR+V2xFZa7S7iIiISPwUPg/AaJxmqaG/J4DbEXkiqWo+RUREROKn8HkARnFD+MzaK3w2NLv7g2FCYbMjiiUiIiLSaSl8HsCems8R0X2N4RM06EhEREQkXgqfLXAGKjBqi8GwQPche/bb9vzI1PQuIiIiEh+FzxYk1+dHNtL7g8MT3W+xGLjskR+b5voUERERiY/CZwtS6rdHNvYabNRI0y2JiIiItI7CZwuiNZ9Z+4dPT+OId9V8ioiIiMRF4bMFKY3hs+GZ7nuLNrur5lNEREQkLgqfzQl6SfQWRLabqfmMPt9d4VNEREQkLgqfzSlZj4UwpjsNknvu93b0+e5qdhcRERGJi8JnMxonlzezhoFh7Pe+qyF86hGbIiIiIvFR+GxG4+TyZvehzb7vUbO7iIiISKsofDbDKPoSaKj5bEa02V3hU0RERCQuCp/7Ms09ze4t1HxGBxyp2V1EREQkLgqf+6rcgeGtJIwVMgc1e4hLk8yLiIiItIrC574C9YT7T2Z30hCwOZs9RE84EhEREWkdhc99dRtE6PvPs3TAzS0eEg2fanYXERERiYvCZytoknkRERGR1lH4bAUNOBIRERFpHYXPVlCfTxEREZHWUfhsBc3zKSIiItI6Cp+t4FKfTxEREZFWUfhsBbee7S4iIiLSKgqfrdD4bHevwqeIiIhIXBQ+W0EDjkRERERaR+GzFfR4TREREZHWUfhshcZ5Pr2BMOGw2cGlEREREek8FD5bobHZHcAXDHdgSUREREQ6F4XPVtg7fNb5gx1YEhEREZHOReGzFSwWA6ct8qNTv08RERGR2Cl8ttKefp8KnyIiIiKxUvhspeh0S371+RQRERGJlcJnK2muTxEREZH4KXy2kiv6iE0NOBIRERGJlcJnK3nU51NEREQkbgqfrdQ44EjN7iIiIiKxU/hsJZcGHImIiIjETeGzlTTgSERERCR+Cp+t1Bg+1edTREREJHYKn63U2OdTo91FREREYqfw2UrRAUfq8ykiIiISM4XPVlKfTxEREZH4KXy2kvp8ioiIiMRP4bOVXNFmd4VPERERkVgpfLaSmt1FRERE4qfw2UrR8KmaTxEREZGYKXy2kkeP1xQRERGJm8JnK7nU7C4iIiISN4XPVnJrwJGIiIhI3BQ+W0lTLYmIiIjEz9bRBeisNNpdRES6CtM0CQaDhELx/ZsWCASw2Wx4vd64z5UjSyz30mq1YrPZMAzjkK6l8NlK7r0GHJmmecg3QkREpCP4/X4KCgqoq6uL+1zTNMnOzmb79u36d7CTi/VeejweevTogcPhaPW1WhU+H3nkEe677z4KCwsZOXIkf/3rXxk/fnyLx1dUVPCb3/yGV155hbKyMnr37s2DDz7I1KlTW13wjtYYPk0TfMFwdACSiIhIZxEOh9myZQtWq5WePXvicDjiCpHhcJiamhoSExOxWNSTrzM72L00TRO/309JSQlbtmxh4MCBrb7ncYfPF154gZkzZ/Loo48yYcIEHnzwQaZMmcL69evp3r37fsf7/X5OP/10unfvzksvvUROTg7btm0jNTW1VQVua4W1hTy39jm+qf+GqbQcjl22PT/wen9I4VNERDodv99POBwmNzcXj8cT9/nhcBi/34/L5VL47ORiuZdutxu73c62bduix7ZG3OHzgQce4JprruGqq64C4NFHH2Xu3Lk88cQT3Hrrrfsd/8QTT1BWVsbHH3+M3W4HoE+fPq0qbHuoD9bzxFdP4MCBaZotHmezWnBYLfhDYeoDIdLasYwiIiKHk4KjxOpw/K7EFT79fj8rVqxg1qxZTQoxefJkli5d2uw5b7zxBhMnTuTaa6/l9ddfp1u3blx66aXccsstWK3N1xb6fD58Pl/0dVVVFRDpDBsIBOIpctyynFlYsODHT0F1AT2Te7Z4rMseCZ/VdT4CCeo+eyRq/H1p698baXu6l12H7uWRIxAIYJom4XCYcDgc9/mNlTSNnyGdV6z3MhwOY5omgUBgvxwX6990XIlp9+7dhEIhsrKymuzPyspi3bp1zZ6zefNm3nvvPS677DLmzZvHxo0b+fnPf04gEGD27NnNnjNnzhzuvPPO/fa/8847rWoWiFeKJYXycDmvLn6Vvra+LR5nhKyAwYJF75Ob2ObFkkOwYMGCji6CHCa6l12H7mXHs9lsZGdnU1NTg9/vb/XnVFdXH8ZSxeacc85h+PDhzJkzp92v3ZUd7F76/X7q6+v54IMPCAaDTd6LddBam1fXhcNhunfvzmOPPYbVamXMmDHs3LmT++67r8XwOWvWLGbOnBl9XVVVRW5uLmeccQbJycltXWTeXPgmy4qWkTU4i6mDW+73+edvPqKytI4xEyYytrca3o9EgUCABQsWcPrpp0e7fUjnpHvZdeheHjm8Xi/bt28nMTGxVf33TNOkurqapKSkdh/tbrPZcDgc7ZILvg1ivZderxe3281JJ5203+9MY0v1wcQVPjMzM7FarRQVFTXZX1RURHZ2drPn9OjRA7vd3qRqdsiQIRQWFuL3+5sdqu90OnE6nfvtt9vt7fIfqt4pvVlWtIyddTsPeD23I/LjC4QN/Qf0CNdevzvS9nQvuw7dy44XCoUwDAOLxdKqvnyNzbONn9HeOuq6XVGs99JisWAYRrN/v7H+Pcd1xxwOB2PGjGHhwoVNCrtw4UImTpzY7DnHH388GzdubNJ/4JtvvjnkOaLaUl5SHgD51fkHPM5tj/z4NNG8iIhIxykvL+eKK64gLS0Nj8fDWWedxYYNG6Lvb9u2jWnTppGWlkZCQgJDhw5l3rx50XMvu+wyunXrhtvtZuDAgTz55JMd9VW+FeJudp85cybTp09n7NixjB8/ngcffJDa2tro6PcrrriCnJycaB+Mn/3sZzz88MP84he/4LrrrmPDhg3cfffdXH/99Yf3mxxGjeFze/X2Ax7XONenHrEpIiJdhWmaMVeqhMNh6v0hbP7gIddAuu3WVjfdX3nllWzYsIE33niD5ORkbrnlFqZOncrXX3+N3W7n2muvxe/388EHH5CQkMDXX39NYmJksMbtt9/O119/zVtvvUVmZiYbN26kvr7+kL6LHFjc4fPiiy+mpKSEO+64g8LCQkaNGsX8+fOjg5Dy8/Ob/ALm5uby9ttvc+ONNzJixAhycnL4xS9+wS233HL4vsVhlpuUC8D2mu2EzTAWo4X5rhofselX+BQRka6hPhDi6Dvebvfrfv27KXgc8Q9FaQydS5Ys4bjjjgPgmWeeITc3l9dee43vfve75Ofnc+GFFzJ8+HAA+vXrFz0/Pz+fY445hrFjxwJH9nSQXUWrBhzNmDGDGTNmNPve4sWL99s3ceJEli1b1ppLdYieCT2xYMEX8lFcV0x2QvP9WRsnlq9T+BQREekQa9euxWazMWHChOi+jIwMBg8ezNq1awG4/vrr+dnPfsY777zD5MmTufDCCxkxYgQQaaG98MILWblyJWeccQbnnXdeNMRK29DklM2wWWykWdIoDZeyrWpbi+HTs9fz3UVERLoCt93K17+bEtOx4XCY6qpqkpKTDkuze1u5+uqrmTJlCnPnzuWdd95hzpw53H///Vx33XWcddZZbNu2jXnz5rFgwQImTZrEtddey5/+9Kc2K8+3nYaItSDDkgHAtqptLR7T+IeiPp8iItJVGIaBx2GLeXE7rHEd39LS2v6eQ4YMIRgM8sknn0T3lZaWsn79eo4++ujovtzcXH7605/yyiuv8Mtf/pLHH388+l63bt2YPn06//nPf3jwwQd57LHHWv8DlINSzWcLGsNnflXLI95dDvX5FBER6UgDBw7k3HPP5ZprruHvf/87SUlJ3HrrreTk5HDuuecCcMMNN3DWWWcxaNAgysvLWbRoEUOGDAHgjjvuYMyYMQwdOhSfz8ebb74ZfU/ahmo+W5Bhbaj5rD54zaea3UVERDrOk08+yZgxYzjnnHOYOHEipmkyb9686LyToVCIa6+9liFDhnDmmWcyaNAg/va3vwGRaSRnzZrFiBEjOOmkk7BarTz//PMd+XW6PNV8tiCWmk+FTxERkY6x9wDntLQ0nn766RaP/etf/9rie7fddhu33Xbb4SyaHIRqPlvQGD63V28nFG4+XLrV7C4iIiISF4XPFqRaUrFb7ATCAQrrCps9RjWfIiIiIvFR+GyBxbCQk5gDtDziXTWfIiIiIvFR+DyA6DPeW+j3qamWREREROKj8HkAjeGzxZpPNbuLiIiIxEXh8wCiNZ/Vzdd8uvSEIxEREZG4KHweQG5SLtBys7tHfT5FRERE4qLweQCNNZ87qncQDAf3ez/a7K7wKSIiIhIThc8DyPJk4bQ6CZpBCmoK9nt/7z6fpmm2d/FEREREOh2FzwOwGJZo03tzj9ls7PMZNsEfCrdr2UREREQ6I4XPgzjQiPfGmk8Ar1/hU0RERORgFD4Pondyb6D5QUd2qwWbxQCgLrB/n1ARERH5dggEAh1dhE5D4fMg8pIbaj6baXYHPeVIRESkI8yfP58TTjiB1NRUMjIyOOecc9i0aVP0/R07dnDJJZeQnp5OQkICY8eO5ZNPPom+/7///Y9x48bhcrnIzMzk/PPPj75nGAavvfZak+ulpqby1FNPAbB161YMw+CFF17g5JNPxuVy8cwzz1BaWsoll1xCTk4OHo+H4cOH89xzzzX5nHA4zB//+EcGDBiA0+kkLy+PP/zhDwCcdtppzJgxo8nxJSUlOBwOFi5ceDh+bEcEW0cX4Eh3oJpPiDS9V3uDmutTRES6BtOEQF1sx4bDkWP9VrAcYn2W3QOGEfPhtbW1zJw5kxEjRlBTU8Mdd9zB+eefz6pVq6irq+Pkk08mJyeHN954g+zsbFauXEk4HOkiN3fuXM4//3x+85vf8PTTT+P3+5k3b17cRb711lu5//77OeaYY3C5XHi9XsaMGcMtt9xCcnIyc+fO5fLLL6d///6MHz8egFmzZvH444/z5z//mRNOOIGCggLWrVsHwNVXX82MGTO4//77cTqdAPznP/8hJyeH0047Le7yHakUPg+isc/nrppdBMIB7BZ7k/cbaz71iE0REekSAnVwd8+YDrUAqYfrur/eBY6EmA+/8MILm7x+4okn6NatG19//TUff/wxJSUlLF++nPT0dAAGDBgQPfYPf/gD3//+97nzzjuj+0aOHBl3kW+44QYuuOCCJvtuuumm6PZ1113H22+/zX//+1/Gjx9PdXU1Dz30EA8//DDTp08HoH///pxwwgkAXHDBBcyYMYPXX3+d733vewA89dRTXHnllRhxBPMjnZrdD6Kbpxsuq4uQGWJXza793t8z16cGHImIiLSXDRs2cMkll9CvXz+Sk5Pp06cPAPn5+axatYpjjjkmGjz3tWrVKiZNmnTIZRg7dmyT16FQiLvuuovhw4eTnp5OYmIib7/9Nvn5kdbTtWvX4vP5Wry2y+Xi8ssv54knngBg5cqVrFmzhiuvvPKQy3okUc3nQVgMC7nJuWwo38C2qm3RZvhGLj3fXUREuhK7J1ILGYNwOExVdTXJSUlYDkezexymTZtG7969efzxx+nZsyfhcJhhw4bh9/txu90HPPdg7xuGsd/83c0NKEpIaFpTe9999/HQQw/x4IMPMnz4cBISErjhhhvw+/0xXRciTe+jRo1ix44dPPnkk5x22mn07t37oOd1Jqr5jEHvpJb7fTbWfNb5NdpdRES6AMOINH/Hutg98R3f0hJHs3JpaSnr16/ntttuY9KkSQwZMoTy8vLo+yNGjGDVqlWUlZU1e/6IESMOOICnW7duFBTsebjMhg0bqKs7eD/YJUuWcO655/KDH/yAkSNH0q9fP7755pvo+wMHDsTtdh/w2sOHD2fs2LE8/vjjPPvss/zwhz886HU7G4XPGERHvDcz16dHfT5FRETaVVpaGhkZGTz22GNs3LiR9957j5kzZ0bfv+SSS8jOzua8885jyZIlbN68mZdffpmlS5cCMHv2bJ577jlmz57N2rVr+fLLL7n33nuj55922mk8/PDDfP7553z22Wf89Kc/xW6371eOfQ0cOJAFCxbw8ccfs3btWn7yk59QVFQUfd/lcnHLLbdw88038/TTT7Np0yaWLVvGP//5zyafc/XVV3PPPfdgmmaTUfhdhcJnDKIj3qv3r/lsfMpRnaZaEhERaRcWi4Xnn3+eFStWMGzYMG688Ubuu+++6PsOh4N33nmH7t27M3XqVIYPH84999yD1Rr5N/uUU07hxRdf5I033mDUqFGcdtppfPrpp9Hz77//fnJzcznxxBO59NJLuemmm/B4Dt4t4LbbbmP06NFMmTKFU045JRqA93b77bfzy1/+kjvuuIMhQ4Zw8cUXU1xc3OSYSy65BJvNxiWXXILL5TqEn9SRSX0+Y3Cgpxx1T4pMhbC5pLZdyyQiIvJtNnnyZL7++usm+/bup9m7d29eeumlFs+/4IIL9hup3qhnz568/fbbTfZVVFREt/v06bNfn1CA9PT0/eYH3ZfFYuE3v/kNv/nNb1o8Zvfu3Xi9Xn70ox8d8LM6K9V8xqCx5rOgtoBAqGmH4wl9MwBYtrm03cslIiIiXUcgEKCwsJDbbruNY489ltGjR3d0kdqEwmcMMt2ZeGwewmaY7TXbm7w3oW86hgEbimsoqfZ1UAlFRESks1uyZAk9evRg+fLlPProox1dnDaj8BkDwzCig472HfGeluDgqOxkAD7ZotpPERERaZ1TTjkF0zRZv349w4cP7+jitBmFzxgdqN/nsf0ik9iq6V1ERETkwBQ+Y3SgZ7xP7Bfp97l0k8KniIiIyIEofMYoOtdn9f41n+Mb+n1uKqmluNrb3kUTERER6TQUPmN0oJrPVI+DIQ39Ppdtbv5pCiIiIiKi8Bmzxj6fhbWF+EL7j2qf2F9TLomIiIgcjMJnjNJd6STaEzEx2V61fb/3j23o97lM/T5FREREWqTwGaO9p1s6UL/PzbtrKapSv08REZEjWZ8+fXjwwQdjOtYwjIM+uUhip/AZh95JLff7THHbGdqzsd+naj9FREREmqPwGYdozWczc33CnimXFD5FREREmqfwGYfoiPfq/Ws+YU+/T833KSIi0nYee+wxevbsSTgcbrL/3HPP5Yc//CGbNm3i3HPPJSsri8TERMaNG8e777572K7/5Zdfctppp+F2u8nIyODHP/4xNTU10fcXL17M+PHjSUhIIDU1leOPP55t2yIVV6tXr+bUU08lKSmJ5ORkxowZw2effXbYytYZKHzG4WA1n+P6pmMxYGtpHQWV9e1ZNBERkcPCNE3qAnUxL/XB+riOb2kxTTPmMn73u9+ltLSURYsWRfeVlZUxf/58LrvsMmpqapg6dSoLFy7k888/58wzz2TatGnk5zdfeRSP2tpapkyZQlpaGsuXL+fFF1/k3XffZcaMGQAEg0HOO+88Tj75ZL744guWLl3Kj3/8YwzDAOCyyy6jV69eLF++nBUrVnDrrbdit9sPuVydia2jC9CZNPb5LK4rpj5Yj9vmbvJ+ssvOsJwUvthRySebyzjvmJyOKKaIiEir1QfrmfDshHa/7ieXfoLH7onp2LS0NM466yyeffZZJk2aBMBLL71EZmYmp556KhaLhZEjR0aPv+uuu3j11Vd54403oiGxtZ599lm8Xi9PP/00CQkJADz88MNMmzaNe++9F7vdTmVlJeeccw79+/cHYMiQIdHz8/Pz+dWvfsVRRx0FwMCBAw+pPJ2Raj7jkOpKJdkRGVTU3KAjUNO7iIhIe7jssst4+eWX8fkic28/88wzfP/738disVBTU8NNN93EkCFDSE1NJTExkbVr1x6Wms+1a9cycuTIaPAEOP744wmHw6xfv5709HSuvPJKpkyZwrRp03jooYcoKCiIHjtz5kyuvvpqJk+ezD333MOmTZsOuUydjWo+49Q7uTdf7v6S/Op8BqcP3u/9if0yeOyDzSzbovApIiKdj9vm5pNLP4np2HA4THV1NUlJSVgsh1aftW9r4sFMmzYN0zSZO3cu48aN48MPP+TPf/4zADfddBMLFizgT3/6EwMGDMDtdnPRRRfh9/sPqYyxevLJJ7n++uuZP38+L7zwArfddhsLFizg2GOP5be//S2XXnopc+fO5a233mL27Nk8//zznH/++e1StiOBwmec8pLz+HL3ly32+xzbJw2rxWBbaR27KurpmRrfH5OIiEhHMgwj5ubvcDhM0BbEY/cccviMl8vl4oILLuCZZ55h48aNDB48mNGjRwOwZMkSrrzyymigq6mpYevWrYflukOGDOGpp56itrY2Wvu5ZMkSLBYLgwfvqZQ65phjOOaYY5g1axYTJ07k2Wef5dhjjwVg0KBBDBo0iBtvvJFLLrmEJ5988lsVPtXsHqcDzfUJkNTQ7xM05ZKIiEhbuuyyy5g7dy5PPPEEl112WXT/wIEDeeWVV1i1ahWrV6/m0ksv3W9k/KFc0+VyMX36dNasWcOiRYu47rrruPzyy8nKymLLli3MmjWLpUuXsm3bNt555x02bNjAkCFDqK+vZ8aMGSxevJht27axZMkSli9f3qRP6LeBwmecDjbiHeDYfumA+n2KiIi0pdNOO4309HTWr1/PpZdeGt3/wAMPkJaWxnHHHce0adOYMmVKtFb0UHk8Ht5++23KysoYN24cF110EZMmTeLhhx+Ovr9u3TouvPBCBg0axI9//GOuvfZafvKTn2C1WiktLeWKK65g0KBBfO973+Oss87izjvvPCxl6yzU7B6ng831CZFBR39/X/0+RURE2pLFYmHXrl377e/Tpw/vvfdek33XXnttk9fxNMPvOw3U8OHD9/v8RllZWbz66qvNvudwOHjuuedivm5XpZrPODXWfO6u301toLbZY8b1ScdqMdheVs+O8rr2LJ6IiIjIEU3hM07JjmTSnGlAy/0+E502hkf7fZa1W9lEREQkPs888wyJiYnNLkOHDu3o4nVJanZvhbzkPMpLytlWvY0hGc13Ep7YP4NV2ytYtrmUi8b0aucSioiISCy+853vMGFC85Pqf9uePNReFD5boXdyb1aXrG6x5hMi/T7/b/EmDToSERE5giUlJZGUlNTRxfhWUbN7K+QlHXzE+9jeadgsBjsr6tlepn6fIiIiIqDw2SrREe8HqPlMcNoY0SvS73Op5vsUERERARQ+W6VxxPuBpluCPc9512TzIiIiIhEKn63Q2Oxe5i2jxl/T4nET+zeEz02l+80RJiIiIvJtpPDZComORNJdkacYbatuud/nmN5p2K0Guyq9bC+rb6/iiYiIiByxFD5bKZZ+nx6HjZG9UgFYunl3exRLRERE5Iim8NlKsYx4h737fWqyeRERkSNFnz59ePDBBzu6GN9KCp+tFEvNJ+zV73Oz+n2KiIiIKHy2UuOI9wP1+QQYnRfp91lQ6WVbqeb7FBERkUMTCoUIh8MdXYxWU/hspVhrPt0OK6NyUwFNuSQiIkc+0zQJ19XFvtTXx3d8C0s8rYOPPfYYPXv23C+AnXvuufzwhz9k06ZNnHvuuWRlZZGYmMi4ceN49913W/0zeeCBBxg+fDgJCQnk5uby85//nJqaprPdLFmyhFNOOQWPx0NaWhpTpkyhvLwcgHA4zB//+EcGDBiA0+kkLy+PP/zhDwAsXrwYwzCoqKiIftaqVaswDIOtW7cC8NRTT5Gamsobb7zB0UcfjdPpJD8/n+XLl3P66aeTmZlJSkoKJ598MitXrmxSroqKCn7yk5+QlZWFy+Vi2LBhvPnmm9TW1pKcnMxLL73U5PjXXnuNhIQEqqurW/3zOhg9XrOVGvt8VvgqqPRVkuJMafHYif0yWL61nKWbS/n++Lz2KqKIiEjczPp61o8eE9c5RYfhuoNXrsDweGI69rvf/S7XXXcdixYtYtKkSQCUlZUxf/585s2bR01NDVOnTuUPf/gDTqeTp59+mmnTprF+/Xry8uL/d9hisfCXv/yFvn37snnzZn7+859z880387e//Q2IhMVJkybxwx/+kIceegibzcaiRYsIhUIAzJo1i8cff5w///nPnHDCCRQUFLBu3bq4ylBXV8e9997LP/7xDzIyMujevTubN29m+vTp/PWvf8U0Te6//36mTp3Khg0bSEpKIhwOc9ZZZ1FdXc1//vMf+vfvz9dff43VaiUhIYHvf//7PPnkk1x00UXR6zz11FNcdNFFbfrIUYXPVvLYPXRzd6OkvoT8qnyGdxve4rHH9svgL+9tjPb7NAyjHUsqIiLStaSlpXHWWWfx7LPPRsPnSy+9RGZmJqeeeioWi4WRI0dGj7/rrrt49dVXeeONN5gxY0bc17vhhhui23369OH3v/89P/3pT6Ph849//CNjx46NvgYYOnQoANXV1Tz00EM8/PDDTJ8+HYD+/ftzwgknxFWGQCDA3/72tybf67TTTmtyzGOPPUZqairvv/8+55xzDu+++y6ffvopa9euZdCgQQD069cvevzVV1/NcccdR0FBAVlZWZSUlPDWW28dUi1xLBQ+D0Fech4l9SVsq952wPA5uncaDquFoiofW3bX0q9bYjuWUkREJHaG283glStiOjYcDlNVXU1yUhIWy6H15DPc7riOv+yyy7jmmmv429/+htPp5JlnnuH73/8+FouFmpoafvvb3zJ37lwKCgoIBoPU19eTn3/grnIteffdd5kzZw7r1q2jqqqKYDCI1+ulrq4Oj8fDqlWr+O53v9vsuWvXrsXn80VDcms5HA5GjBjRZF9RURG33XYbixcvpri4mFAoRF1dXfR7rlq1il69ekWD577Gjx/P0KFD+de//sXNN9/Mf//7X3r37s1JJ510SGU9GPX5PASx9vt02a2MyksFNOWSiIgc2QzDwOLxxL643fEd38ISb6vgtGnTME2TuXPnsn37dj788EMuu+wyAG666SZeffVV7r77bj788ENWrVrF8OHD8fv9cf88tm7dyjnnnMOIESN4+eWXWbFiBY888ghA9PPcBwjOB3oPiIb2vfu8BgKBZj9n35/R9OnTWbVqFQ899BAff/wxq1atIiMjI6ZyNbr66qt56qmnAHjmmWe48sor27yFVuHzEMQ61ydE+n0CLNWgIxERkUPmcrm44IILeOaZZ3juuecYPHgwo0ePBiKDf6688krOP/98hg8fTnZ2dnTwTrxWrFhBOBzm/vvv59hjj2XQoEHs2rWryTEjRoxg4cKFzZ4/cOBA3G53i+9369YNgIKCgui+VatWxVS2JUuWcP311zN16lSGDh2K0+lk9+49D7UZMWIEO3bs4JtvvmnxM37wgx+wbds2/vrXv7J+/XquuOKKmK59KFoVPh955BH69OmDy+ViwoQJfPrppzGd9/zzz2MYBuedd15rLnvEibXmE/aebF7zfYqIiBwOl112GXPnzuWJJ56I1npCJPC98sorrFq1itWrV3PppZe2emqiAQMGEAgE+Otf/8rmzZv597//zaOPPtrkmFmzZrF8+XJ+/vOf88UXX7Bu3Tr+7//+j927d+Nyubjlllu4+eabefrpp9m0aRPLli3jn//8Z/Tzc3Nz+e1vf8uGDRuYO3cu999/f0xlGzhwIP/+979Zu3Ytn3zyCZdddlmT2s6TTz6Zk046iQsvvJAFCxawZcsW3nrrLebPnx89Ji0tjQsuuICbb76ZU089lV69erXq5xSPuMPnCy+8wMyZM5k9ezYrV65k5MiRTJkyheLi4gOet3XrVm666SZOPPHEVhf2SLP3XJ8HC5TH5KXisFkoqfaxeXdtexRPRESkSzvttNNIT09n/fr1XHrppdH9DzzwAGlpaRx33HFMmzaNKVOmRGtF4zVy5EgeeOAB7r33XoYNG8YzzzzDnDlzmhwzaNAg3nnnHVavXs348eOZOHEir7/+OjZbZGjN7bffzi9/+UvuuOMOhgwZwsUXXxzNTXa7neeee45169YxYsQI7r33Xn7/+9/HVLZ//vOflJeXM3r0aC6//HKuv/56unfv3uSYl19+mXHjxnHJJZdw9NFHc/PNN0dH4Tf60Y9+hN/v5wc/+EGrfkbxMsw4q+EmTJjAuHHjePjhh4FIZ+Pc3Fyuu+46br311mbPCYVCnHTSSfzwhz/kww8/pKKigtdeey3ma1ZVVZGSkkJlZSXJycnxFLdVAoEA8+bNY+rUqdjt9haPqw/WM/6Z8QB8cPEHpLnSDvi5339sKcs2l/H784bxg2N7H9YyS/NivZdy5NO97Dp0L48cXq+XLVu20LdvX1wuV9znh8NhqqqqSE5OPuQBR9Jx/v3vf3PjjTfy9ddfk5mZecB7eaDfmVjzWlyj3f1+PytWrGDWrFnRfRaLhcmTJ7N06dIWz/vd735H9+7d+dGPfsSHH3540Ov4fD58Pl/0dVVVFRD5D1ZznXAPt8ZrHOxaNmxkebIoqitiU9kmRnYbecDjx/dOY9nmMpZu3M3FY3oetvJKy2K9l3Lk073sOnQvjxyBQCAyqXw43Kpm6cb6q8bPkM6lrq6OgoIC7rnnHq655hocDsdB72U4HMY0TQKBAFartcl7sf5NxxU+d+/eTSgUIisrq8n+rKysFidL/eijj/jnP/8Zc+dZgDlz5nDnnXfut/+dd97BE+MEtIfDggULDnqMxx8pz/8++h87nTsPeKxZBWBj0boCXnljBy5NdNVuYrmX0jnoXnYdupcdz2azkZ2dTU1NTatGgjdqy6fhtLX//ve/zJw5s9n3cnNzD1i51tndc8893H///Rx33HFce+21wMHvpd/vp76+ng8++IBgMNjkvbq62B4j3qbxp7q6mssvv5zHH3+czMzMmM+bNWtWk1+EqqoqcnNzOeOMM9qt2X3BggWcfvrpB20S+ubzb9iydgv5SfncNvm2A39uKMwbBR+zrayOdfb+/PqswYez2NKMeO6lHNl0L7sO3csjh9frZfv27SQmJraq2d00Taqrq0lKSuq0D1C5+OKLOeWUU5p9z263t0vu6Ch33303d999NxD7vfR6vbjdbk466aRmm91jEVf4zMzMxGq1UlTU9EFaRUVFZGdn73f8pk2b2Lp1K9OmTYvua6zKtdlsrF+/nv79++93ntPpxOl07rffbre363+oYrne5UMv59n1z/JZ8Wd8UfYFY7JafiSZ3Q6/O28Y05/4lKeX5XPx+DyOyu66v9RHkvb+3ZG2o3vZdehedrxQKBSZ19NiaVWfzcZ/0xs/ozNKSUkhJaXlR2R/W8R6Ly0WC4ZhNPv3G+vfc1y/KQ6HgzFjxjSZqyocDrNw4UImTpy43/FHHXUUX375JatWrYou3/nOdzj11FNZtWoVubm58Vz+iJSdkM35A84H4O+r/37Q408e1I2zhmUTCpvc/toaTbskIiIdTv8WSawOx+9K3P+bMnPmTB5//HH+9a9/sXbtWn72s59RW1vLVVddBcAVV1wRHZDkcrkYNmxYkyU1NZWkpCSGDRuGw+E45C9wJPjR8B9hM2wsLVjK6pLVBz3+9nOOxuOwsnxrOS+vPHA/URERkbbSWFMVa189kcbflUNptYi7z+fFF19MSUkJd9xxB4WFhYwaNYr58+dHByHl5+d32qr31spJzGFa/2m8uvFV/r767/xt8t8OeHzPVDfXTxrIPW+tY868tZw+JIsUj5qeRESkfVmtVlJTU6NzTnrifMxlOBzG7/fj9Xq/df/2dzUHu5emaVJXV0dxcTGpqan7jXSPR6sGHM2YMYMZM2Y0+97ixYsPeG7j80O7mquHX83rm17nw50f8tXurxiaOfSAx//w+L68tGIHG4truO+ddfz+vOHtVFIREZE9GsdsHOxhMc0xTZP6+vpmnzsunUus9zI1NbXZcT7x0GQ/h0lech5n9z2b/23+H3//4u/85bS/HPB4h83CXecO45LHl/HMJ/l8b2wuI3qltk9hRUREGhiGQY8ePejevXvcc68GAgE++OADTjrpJA0e6+RiuZd2u/2QajwbKXweRlePuJo3N7/Jou2LWF+2nsHpB55KaWL/DM4d1ZPXV+3i9tfW8MrPj8dq0f85iohI+7NarXEHC6vVSjAYxOVyKXx2cu15L9VB4zDql9KPM/ucCcDfvzj4yHeA30wdQpLTxuodlTy/PL8tiyciIiLS4RQ+D7NrRlwDwIJtC9hYvvGgx3dPdjHzjEEA/HH+ekprfAc5Q0RERKTzUvg8zAamDeT03qcD8NiXj8V0zuXH9uboHslU1ge4d37zjykVERER6QoUPtvAj0f8GID5W+azuXLzQY+3WS3cdd4wAP772Q5WbCtr0/KJiIiIdBSFzzZwVPpRnJJ7CiYm//jiHzGdM6Z3Gt8b2wuA2177imAo3JZFFBEREekQCp9t5KcjfgrAvC3zyK+KbSDRLWceRYrbztqCKv69bFtbFk9ERESkQyh8tpGhmUM5IecEQmaIf3wZW+1nRqKTm8+MTM/0wDvfUFzlbcsiioiIiLQ7hc829JMRPwHgf5v+x86a2J7h/v1xeYzslUK1L8gf5q1ty+KJiIiItDuFzzY0qvsoju1xLEEzyD+//GdM51gtBr8/bziGAa+v2sXHm3a3cSlFRERE2o/CZxv76chI389XN75KYW1hTOcM75XCDyb0BuCO17/CH9TgIxEREekaFD7b2JisMYzNGkswHOSJNU/EfN5NZwwmI8HBxuIa7nh9DeGw2YalFBEREWkfCp/toLH28+VvXqakriSmc1I8dv5w/nAsBjy/fDu/ee1LBVARERHp9BQ+28H47PGM6jYKf9jPk189GfN5Zw7L5oHvjcJiwHOfKoCKiIhI56fw2Q4Mw4jWfr64/kVK60tjPve8Y3IUQEVERKTLUPhsJ8f1PI7hmcPxhrz86+t/xXWuAqiIiIh0FQqf7cQwjOi8n//5+j+sLFoZ1/kKoCIiItIVKHy2o5N6ncTkvMkEwgF+segXbK/aHtf5CqAiIiLS2Sl8tiPDMLj7xLsZmjGUCl8F1753LZW+yrg+QwFUREREOjOFz3bmtrn562l/JcuTxZbKLfxy8S8JhANxfYYCqIiIiHRWCp8doJunG49MegSPzcMnhZ/w+2W/xzTjC48KoCIiItIZKXx2kMHpg7nv5PuwGBZe2fAKT331VNyfoQAqIiIinY3CZwc6qddJ3DzuZgD+vOLPLNy2MO7P2DeA/uqlL/AGQoe7qCIiIiKHhcJnB7v0qEu5ePDFmJjc+uGtfFX6VdyfsXcAfXnlDs59eAnrC6vboLQiIiIih0bhs4MZhsGt42/l+Jzj8Ya8XLfwOgprC+P+nPOOyeGpq8aTmehkfVE10x7+iKeXbo27L6mIiIhIW1L4PALYLDb+dNKfGJA6gJL6EmYsnEFtoDbuzzlpUDfm33Aipwzuhj8Y5o7Xv+Kapz+jrNbfBqUWERERiZ/C5xEi0ZHII5MeId2Vzvry9dz8wc2EwvH33cxMdPLkleO445yjcVgtvLu2mDMf/IAlG3e3QalFRERE4qPweQTpmdiTv5z2F5xWJx/s+IA/ffanVn2OYRj88IS+vHbt8fTvlkBxtY8f/PMT7nlrHYFQ+DCXWkRERCR2Cp9HmJHdRvL7E34PwH/W/ofn1z3f6s86umcyb153IpeMz8M04dH3N3HR/33M1t3xN+mLiIiIHA4Kn0egM/ucyfXHXA/APZ/ew7NrnyVstq7G0u2wMueC4Tz6g9GkuO2s3lHJ2X/5kJdX7NBgJBEREWl3Cp9HqKuHX825/c8lZIaY8+kcrn7nanZU72j15505rAdv/eJExvdNp9Yf4pcvruaGF1ZRrsFIIiIi0o4UPo9QhmHwu+N/x63jb8Vtc7O8cDkXvHEBL6x7odW1oD1T3Tx3zbH88vRBWC0Gr6/axSl/WswTH21RX1ARERFpFwqfRzCLYeGyIZfx8rSXGd19NPXBen7/ye/58YIfs6tmV6s+02oxuG7SQP77k4kclZ1EZX2A3735NVMe/ID31hWpKV5ERETalMJnJ5CbnMuTZz7JLeNuwWV18UnBJ5z/+vn8d/1/Wx0Wx/ROY+71JzLnguFkJDjYXFLLD5/6jCue+JRvivR0JBEREWkbCp+dhMWw8IOjf8BL33mJY7ofQ12wjruW3cVPFvyEgpqCVn2m1WJwyfg8Fv3qFH5ycj8cVgsfbtjNWQ99yO2vrdHk9CIiInLYKXx2Mr2Te/PklCf51dhf4bQ6WVqwlPPfOJ+Xvnmp1bWgyS47s84awoKZJ3Hm0GxCYZN/L9vGyfct4h8fbsYfVH9QEREROTwUPjshq8XKFUOv4MVpLzKy20hqA7XcufROfvbuz1r1XPhGvTMSePTyMTx3zbEc3SOZam+Q389dy5QHP+Ddr9UfVERERA6dwmcn1jelL/8681/8cswvcVgcLNm1hGmvTuOhlQ9R5a9q9edO7J/B/647gXsvHE5mopMtu2u5+unP+P5jy/how26FUBEREWk1hc9OzmqxcuWwK3nxOy8yuvtovCEv//jyH5z18lk8teYpfCFfKz/X4OJxeSy66WR+dkp/HFYLn2wp4wf//ITzHlnC218VEg4rhIqIiEh8FD67iH4p/XjqzKd46NSH6J/Snyp/FfevuJ+zXzmbVze8SjAcbNXnJrns3HLmUSz61SlceVwfXHYLq3dU8pN/r2DKgx/w6uc7CGqOUBEREYmRwmcXYhgGp+WdxsvfeZnfHfc7shOyKaor4o6P7+DCNy5kYf7CVjeZ56S6+e13hvLRLadx7an9SXLa2FBcw40vrOaUPy3m38u24Q2EDvM3EhERka5G4bMLslqsnD/wfN48/01uGnsTKc4UNldu5oZFN3D5W5fzWeFnrf7szEQnv5pyFEtmncbNZw4mI8HBjvJ6bn9tDSf+cRF/f38TNb7W1bKKiIhI16fw2YU5rU6mD53OvAvmcc3wa3BZXawuWc1Vb1/FtQuv5Zvyb1r92ckuOz8/ZQAf3XIad35nKDmpbkqqfcx5ax3HzVnIA++sp7jaexi/jYiIiHQFCp/fAsmOZK4ffT3zLpjH9wZ9D6th5YMdH3DRGxfxy8W/ZH3Z+lZ/ttthZfpxfVj8q1P403dH0q9bAlXeIH95byPH3/Me1z/3OZ9tLdMIeREREQEUPr9Vunm6cfvE23n9vNeZ0mcKJibvbHuHi/53EdctvI4vSr5o9WfbrRYuGtOLBTeezP9dNprReakEQiZvrN7FRY8u5ey/fMTzn+ZT71e/UBERkW8zhc9vod7JvfnTyX/i5e+8zFl9zsJiWFi8YzGXzbuMH7/z40PqE2q1GJw1vAev/Px43rzuBL43thdOm4WvC6q49ZUvmXD3u/z+za/Zurv2MH4jERER6SwUPr/FBqUN4o8n/5HXz32d8wach82wsbRgKVe9fRXT35rOkp1LDqm5fFhOCn+8aCSf/HoSv5k6hLx0D1XeIP/4aAun/Gkx05/4lPfWFRHSfKEiIiLfGgqfQp+UPtx1/F28ecGbXDz4YuwWOyuLV/LTd3/KJXMv4b389wibrZ/LM9Xj4JqT+rH4plN48spxnDK4G4YB739Twg+f+oxT/rSIvy3eyK6K+sP4rURERORIpPApUTmJOdx27G3Mv3A+Vxx9BW6bm69Kv+IXi37BhW9cyKsbXqXCW9Hqz7dYDE49qjtPXTWexTedwjUn9iXFbWd7WT1/nL+e4+99j0sfX8aLn23XdE0iIiJdlK2jCyBHnu6e7vxq3K/40fAf8Z+v/8Oz655lY8VG7vj4DqyGlbFZY5nUexKn5Z5GVkJWq67ROyOB35x9NDNPH8z/Vu/ipZU7+HRLGR9vKuXjTaXc/voazjg6m/NH53DigExsVv1/koiISFeg8CktSnelc/3o65k+dDovfvMi87fMZ335ej4p/IRPCj/h7k/uZkTmCCb1nsSkvEn0Tu4d9zXcDivfG5fL98blsr2sjtdX7eSVz3eyuaSWN1bv4o3Vu8hMdPKdkT25YHQOQ3smYxhGG3xbERERaQ8Kn3JQKc4Urh5+NVcPv5rt1dt5L/893t32LqtLVvPF7i/4YvcX/HnFnxmQOoDJvSczKW8Sg9MGxx0Sc9M9zDhtINeeOoAvdlTy6uc7eWP1LnbX+HhiyRaeWLKFQVmJnH9ML84Z0YPcdE8bfWMRERFpKwqfEpfcpFymD53O9KHTKakrYdH2RSzMX8inBZ+ysWIjGys28ujqR8lJzGFy3mQm957MiG4jsBixN5sbhsHI3FRG5qbym7OH8ME3Jbzy+U4WfF3EN0U13Dt/HffOX8fI3FTOGd6Ds4Zn0ytNQVRERKQzUPiUVuvm6cb3Bn+P7w3+HpW+Sj7Y8QEL8xeyZOcSdtbs5F9f/4t/ff0vuru7c1reaZze+3RGZ43GZon9185utTBpSBaThmRRWR/grS8LeH3VLj7ZUsrq7RWs3l7BH+atZVRuKueM6MHU4T3omepuw28tIiIih0LhUw6LFGcK0/pPY1r/adQH61mycwnv5r/L+9vfp7i+mOfXP8/z658nzZnGqXmnMjlvMhN6TMBhdcR+Dbed74/P4/vj8yip9jH/q0LmfrGLT7aUsWp7Bau2V/D7uWsZnZfK2SN6MnV4Npke/YqLiIgcSfQvsxx2bpubyb0jTe7+kJ9lBctYmL+Q9/Lfo9xXzisbXuGVDa+QaE/k5NyTmZw3meNzjsdti73GsluSk8uP7c3lx/amuNrL/DWFzP2igE+3lrEyv4KV+RXc9ebXjM5LJc8wOLq0loHZqW33pUVERCQmCp/SphxWByf1OomTep3E7cfezoqiFSzYtoD38t+jpL6EuZvnMnfzXDw2D5PyJjG131SO7XFsXE3z3ZNcXDGxD1dM7ENxlZe3GoLo8m0NQRQrrz24hH7dEph0VHcmDclibO80Td8kIiLSARQ+pd3YLDYm9JjAhB4T+PWEX/NFyRe8u+1d3s1/l501O/nf5v/xv83/I92Vzpl9zmRqv6mMyBwR16j57skuph/Xh+nH9aGw0subq3fw3yVr2VxtZXNJLZtLtvD4h1tIdtk4ZXB3Jg3pzimDupPisbfhNxcREZFGCp/SISyGhVHdRzGq+yh+OfaXrC5ZzdzNc3l769uUect4dt2zPLvuWXol9mJqv6mc3e9s+qX0i+sa2Skupk/sTbfyrzjxtEks3VLJwrVFLFpfTHldIDqPqNViMLZ3GpOGRGpF+2UmaC5RERGRNqLwKR3OMIxoEL15/M0s27WMeVvmsTB/ITtqdvDYF4/x2BePMSR9CGf3O5sz+5wZ95OVklx2zh7Rg7NH9CAUNvk8v5yF64pZuDYyfdMnW8r4ZEsZd89bR88UFxP7Z3L8gAyOH5BJVrKrjb65iIjIt4/CpxxR7BY7J/Y6kRN7nUhdoI7F2xczb8s8luxcwtqytawtW8ufPvsTvZN7MzxzOMMzhzOi2wgGpw3Gbo2t6dxqMRjbJ52xfdK55cyjyC+t4711RSxcV8yyzaXsqvTy8sodvLxyBwD9uyVwXEMYPbZfBqme2Efoi4iISFMKn3LE8tg9TO03lan9plLuLeedre8wb8s8VhavZFvVNrZVbePNzW8CkdA6JH0Iw7s1BNLMEfRK6hXTdfIyPFx5fF+uPL4v9f4Qy7c2PmN+N1/urGRTSS2bSmr597JtGAYM7ZnM8f0zOW5AJuP6pOFx6M9IREQkVvpXUzqFNFcaFx91MRcfdTEV3gq+3P1lk6XSVxl91Gf0HGcaQzOG4va6GVA+gKO7HX3Qvpxuh5WTBnXjpEHdAKisC7BsSykfb9zNkk2lbCyuYc3OKtbsrOLvH2zGbjUY2SuVif0zmNg/g9F5abjs1jb9WYiIiHRmCp/S6aS6UqNN8wCmabK9ejtf7P6CL0siYXRd2TrKfeV8tOsjABa8tYDu7u4cn3M8J/Y6kWN7HEuSI+mg10rx2JkyNJspQ7MBKK7yRmtFl2wsZWdFPZ9tK+ezbeX89b2NOGwWRuelMrFfJscNyGBkr1QcNk3pJCIi0kjhUzo9wzDIS84jLzmPc/qdA4A/5Gd92Xo+L/qcN1a/wTZzG8X1xby68VVe3fgqNsPGyO4jOTHnRE7IOYFBaYNiGuHePdnFecfkcN4xOZHQW1bP0s27WbqplKWbSymq8rFscxnLNpfx53fBbbcytk8ax/bL4Lj+GQzLScGu+UVFRORbrFXh85FHHuG+++6jsLCQkSNH8te//pXx48c3e+zjjz/O008/zZo1awAYM2YMd999d4vHixwODquD4d2Gc1TqUaRsSmHSlEl8UfoFH+78kI92fsTWqq2sKFrBiqIVPLjyQbp7unNCzgkc3/N4hmUOo0dCj4OGUcMwyMvwkJeRx8Xj8jBNk827a6NBdNmmUkpr/Xy4YTcfbtgNgMdhZUzvNMb1SWd833RG5aaqmV5ERL5V4g6fL7zwAjNnzuTRRx9lwoQJPPjgg0yZMoX169fTvXv3/Y5fvHgxl1xyCccddxwul4t7772XM844g6+++oqcnJzD8iVEDsZpdXJcznEcl3Mct3AL26u389HOj/ho50d8WvApxXXF0cd+AiTaExmUNoiBaQMZlDYoup1gT2jxGoZh0L9bIv27JfKDY3tjmibfFNWwdNNulm4u5ZMtZVTUBZqEUYfVwsjcFMb3TWd83wzG9E4j0akGCRER6bri/lfugQce4JprruGqq64C4NFHH2Xu3Lk88cQT3Hrrrfsd/8wzzzR5/Y9//IOXX36ZhQsXcsUVV7Sy2CKHJjcpl0uOuoRLjroEX8jHisIVfLjzQ5YXLmdT5SZqAjWsLF7JyuKVTc7LScyJhtFBaYMYljmMnok9m72GYRgMzk5icHYSVx7fl3DYZENxDZ9uiQTRT7eUUVztY/nWcpZvLeeRRZuwGDAsJ4XxfdIZ2yeNY/LSNM+oiIh0KXGFT7/fz4oVK5g1a1Z0n8ViYfLkySxdujSmz6irqyMQCJCent7iMT6fD5/PF31dVVUFQCAQIBAIxFPkVmm8RntcS9pWLPfSgoVx3ccxrvu4yLHhANuqtrGhYkNkKd/ANxXfUFJfws6aneys2cmi7Yui5/dK7MW4rHGMyxrH2KyxZLozW7xWvwwX/TJy+P7YSJ/R/LJ6Pt1azvJtkQC6o7yeL3ZU8sWOSv7x0RYAeqS4GNUrhVG5KYzKTWVojySc38Kmev1ddh26l12H7mXXcTjuZaznGqZpmrF+6K5du8jJyeHjjz9m4sSJ0f0333wz77//Pp988slBP+PnP/85b7/9Nl999RUuV/M1Or/97W+5884799v/7LPP4vF4Yi2uyGFVG66lKFREYbiQwtCeJUy4yXHdLd3pZ+tHP1s/+tj64LHE/jtb7oNNVQabqg22VhsU1IFJ076nVsMkxwN9kkx6J5r0STLJcIKeCCoiIh2prq6OSy+9lMrKSpKTk1s8rl07l91zzz08//zzLF68uMXgCTBr1ixmzpwZfV1VVUVubi5nnHHGAb/M4RIIBFiwYAGnn346dntsT82RI1Nb38vaQC2fF3/O8qLlLC9azvry9RSHiyn2F7PMvwwDg8FpgxmXNY4xWWMYnDaY7u7uMT87vtYXZM2uKlZtr2TV9go+315Jaa2f/FrIr93zGekJdobnpDAyJ4URvZIZnpNCekLXehKT/i67Dt3LrkP3sus4HPeysaX6YOIKn5mZmVitVoqKiprsLyoqIjs7+4Dn/ulPf+Kee+7h3XffZcSIEQc81ul04nQ699tvt9vb9Ze7va8nbaet7mWqPZVT+5zKqX1OBaDCW8FnRZ/xScEn0f6j68rXsa58Hf9e928AkuxJ9EvtR//U/vRP6c+A1AH0S+1Hlidrv1CaardzwiA3JwyKPMveNE12lNfz+fYKPs8vZ9X2Cr7aWUVZbYD3v9nN+9/sjp6bl+5hZG4qI3s1NNf3TMHt6PzN9fq77Dp0L7sO3cuu41DuZaznxRU+HQ4HY8aMYeHChZx33nkAhMNhFi5cyIwZM1o8749//CN/+MMfePvttxk7dmw8lxTpVFJdqUzuPZnJvScDUFJXwvLC5Xxa+Ckri1eSX5VPdaCa1SWrWV2yusm5zYXSAWkD6ObuFg2lhmGQm+4hN93Dd0ZGBjr5giG+3lXFFzsqWb29glU7KthcUkt+WR35ZXX8b/UuIPJM+0FZSYzKTWFEr1SG9UxhUHYiTlvnD6QiItJ5xN3sPnPmTKZPn87YsWMZP348Dz74ILW1tdHR71dccQU5OTnMmTMHgHvvvZc77riDZ599lj59+lBYWAhAYmIiiYmJh/GriBx5unm6RZ9PD5HJ77dVbWNTxSY2Vmxkc+VmNlZsPGAoTXGmRIJo6gAGpg5kQFpkO8WZAoDTZuWYvMjI+EaV9QG+3FHJ6h0VrNoeWUqqfawtqGJtQRXPfbodALs1MiJ/WM8UhuWkMDwnhcHZSZp7VERE2kzc4fPiiy+mpKSEO+64g8LCQkaNGsX8+fPJyoo0C+bn52Ox7HmCy//93//h9/u56KKLmnzO7Nmz+e1vf3topRfpZBxWBwPTBjIwbWCT/fuG0sZ1fnU+lb7K6IT4e+vu7h4Nov1T+9PN3Y10dzoZrgzSXemcMDCTEwZGRt6bpklhlTdSM7q9kjU7K/lyZyWV9YHos+pZHgmkNovBwKwkhuckMywnEkqPyk7C49D8oyIicuha9a/JjBkzWmxmX7x4cZPXW7dubc0lRL5VWgqlvpCPLZVb2FC+gY0VGyNL+UZ21e6iuL6Y4vpiPt71cbOfmWRPIsMdCaLprvTodp++6Zw0Io+hGROoqrNHg+iaXVWs2VlJWa0/WkP63892AJGR9H0yEjgqO4mjspMZ0iOJIT2S6ZXmjnnwlIiICOjZ7iJHNKfVyVHpR3FU+lFN9tf4a/aE0YqNbK3cSqm3lLL6Msq8ZQTNINWBaqoD1Wyt2tri5/dO7s2wzGEM7z2cKWOGMTjtREprTNbsrNyz7KqipNrHlt21bNldy1trCqPnJzptkUDaozGUJjM4O0lPaRIRkRbpXwiRTijRkcio7qMY1X3Ufu+FzTDV/mpKvaWU1pdS5i2LLqX1kX2NTfrbqraxrWobczfPBcBmsTE4bXAkkPYbzvnjh9MnZSxltQHWFVSzrrCKtQXVrC2oYmNxDTW+IJ9tK+ezbeVNytArzc1RDU93GpQVCab9uiVgt1r2K6+IiHy7KHyKdDEWw0KKM4UUZwr9Uvq1eFylr5I1u9fw5e4vo+sybxlflX7FV6Vf8cL6FwBIsCfQL6UffVP60i+1H+f07sd1KX3J8vQkv9TXJJCuLaiiuNrHjvJ6dpTX8+7a4uj17FaDfpmJ0UeOHtUQTHNS3VgsaroXEfm2UPgU+ZZKcaZwfM7xHJ9zPBAZlFRQW9AkjH5d+jW1gVq+3P0lX+7+ssn5doud3sm9I6E0ux/fG9yXfin9SLH1JL80yPrCatYVVvNNUTXrC6up8QVZX1TN+qJq2GtAv8dhZUD3RAZ2T2JgViIDG7Z7pSmUioh0RQqfIgJE5hDtmdiTnok9mdJnCgDBcJCtlVvZXLmZzZWb2VK5Jbp4Q95on9N9dXN3Izcpl7ysPM4ckMc1Sbm46EFNTQr5pSbrCyOBdFNJDXX+UPR59ntz2S1NQmm/dDcl9RAKm2gqaxGRzkvhU0RaZLPYItM5pQ1osj9shimoLWBzxZ5Q2hhQK32VlNSXUFJfwsrilft9ZrornV7JvTgmJ4+zE3rhIAOfN4mKqgQKy1xsLvazuaQWbyC8ZxqoPSXij2sW0r9bYkMwbViyEumdoT6lIiKdgcKniMTNYljIScwhJzGHE3ud2OS9Sl8l26u3k1+VT351fpPtvQc/fVHyRbOfnZqdyoh+WaQ4umMLpxEKpFBTk0BxmZsdJVb8wUTWFoRYW9D0GcI2i0GfzIRoIO3fPZH+3RLpk5mg0fciIkcQ/RdZRA6rxsFOwzKH7fdebaC2SRjdUb2DwtpCCmoLKKwtpC5YR4WvggpfBbC+6cnJ4EwGJ2A17LgsSVjCiQQDHurqXQQCHvJDCWzbkcCCbQmYwQTCgQzMYBLdk9z0zUygX7cE+mYm0Dczkb6ZkceU6vGiIiLtS+FTRNpNgj2h2XlLITLgqTpQTUFNAUV1RRTWFjYJpoW1hRTVFBEgQMgMUBsqA8rABkYSOFq4phm2U+NPZ7U/k1VbMwh/k0nYn0HYn4kRSqJXWmJDIE2gT4aH3pkJ9MlIoFeaW834IiJtQOFTRI4IhmGQ7EgmOT2ZwemD93s/EAgwb948Tj3jVGpDtZT5yij3lkeXCl8FZd6y6HZJfQkFNQUELQGsriKsrqL9PtMM29ntT6e4NpNlFWmE16VgBlIIB1OwhFLokZhFn4wk+mYm0DujIZxmJJCb7laNqYhIKyl8ikin4ra5SXYn0yOxx0GPDYQDFNQURCfU3169PbreWb3zgMEUoNw0KAsmsqIghXB+CmYwBTOYjBlMId3ZjV5JPeif3pN+mWn0TveQ1xBO1cdURKRl+i+kiHRZdoudvOQ88pLzOCHnhCbvBcIBCmsK2VYdecpTYW0hRbVFkSb/ukKKa4sJEsSwV4O9Gqt7R5Pz64BvgG9qwKzwEA4mYwaTCQdScFvSyHB1p2diNn3TejAooxcDM7PIy/DQPcmFVfOXisi3mMKniHwr2S12cpNzyU3O3S+YQmQ6qXJvOUV1RdFQ2tgXdUd1IYU1RZR6iwmYPgxbHVZbHRB57n0IKAaKA7CqOPLCNK2YwUQIJuO0pJJsSyfdnUGPxCzykrPon96DId17MSAjG6etpR6sIiKdn8KniEgzLIaFDHcGGe4Mjs44utljGgdJFdUWUVxXTFFdEflVBWwt38WO6kJ21xdTFdhNgBoMI4RhrwR7JQG2UwqU+mFDw7gptu75XCOcgMNIJsGWSqozjW7uDHomZZKbkkXv1O5kujNId6WT7k4nyZ6EYagmVUQ6D4VPEZFWig6SciQzMG1gi8f5Q35K60sprC1iY1kBm0oL2F5VRFFtMWXeUqqDZfjMCsKWagwjjGmpxUctvlABZXWwuQ4obaEMWEmwJZPiSCXDk06WJ4N0dxqpzlTSXA1rZxqprsg6w52Bw6qaVRHpOAqfIiJtzGF10COxBz0Se3BM1qgWj/MFg3xTUsg3JYVsKi9ke2UJhTW72V2/m0p/OfWhSgxrDYatNrK2+jAJURMspyZYzs66LTGVJ8WZQjd3NzLcGXRzd2u67dmznWhPVK2qiBx2Cp8iIkcIp83G8B69GN6jV7PvB0Nhiqp97CirY0d5PVvLKthaXsyOqt0U1ZRS6i0nbNRgWOswrLUYtoa1tTayz1aLYYSo9FVS6atkY8XGA5bHYXGQ5kqLLM60/bbTXemkOlNJd6WT5kojxZmCxdDcqCJyYAqfIiKdhM1qISfVTU6qmwkANA2pobBJSbWPHeV17KyoZ0d5ZIls17GzvA5fuBaLrRrDVoVhq8GwVTW83rNY7dVg8eIP+6MDrWIqn2Ej3Z1OpjuTTHdmtEZ139cptpTD/rMRkc5D4VNEpIuwWgyyU1xkp7gY28z7pmlSWutnZ3k9uyrqowG1cXvn7noq6gKRgw1/Q+1pQ82pbe8a1Rqs1jrsznqstlpMSy1BagmaQYrriimuKz5oWW3YuO+l+3Db3bhtLS8emwe33U2KI/LY1lRnauQRro4UUlwpJNoTVdsq0skofIqIfEsYhkFmopPMRCcjc1ObPabWF2RXRT07KuopqvRSVOWjsMpLcZWXourI6901Pkxz3zNDDTWpkdpTi60aw1qNzVGLy1WD1V4L1ioCVBLCT5Aglf5KKv2Vh/SdLIYlGkyTncmkOlOjS3TAVUNXgcZBV8mOZKwWPaFKpKMofIqISFSC08bArCQGZiW1eEwgFGZ3jY+iKh9FVV6KqrwUVnoprvZFloZ95XUB/EQm5N/DBIsPw+LFsPjB4sew+HA5QqQkmCS7TRLcITzOEE5HCLstiM3mJ0gd3nA1NYEqKnwVVPoqqQ/WR+Zj9ZVT7iuP+TsaGNFa1FRnKgmOBDw2T2Sxe0iwJ0S3G2tePbbI/kR7YjTUatYAkdZR+BQRkbjYrRZ6pLjpkeI+4HHeQIiSfQJpUbWPgvI6vt66k5AjieJqH9V1QWrroLYCdh3k2skuG92TXQxIcpKZZCE1IYjH48Pt8mO312Ox1YGljrpgFeW+ciq8FZT5yqjwVlDuK6faX42JSYWvggpfxSH9HBLsCftNZbX3OtWZGgmvjV0I7J4mXQpsFv0TLN9O+s0XEZE24bJbyU33kJvuabI/EAgwb952pk49HrvdTp0/GGner/RSXB2pRW1Sq1oVqVX1B8NUeYNUeWvYWFzTzBXtQAqQgsfRi+5JTronueiW5GRgkpPu6U4yEm0kuHw4nPVYbXWEjFrqg3XUBeuoC+xZ1wfrqQ3U7re/yl9Fpa+SkBmiNlBLbaCWnTU7W/XzsVvsTcJooj2RZGcyKY5IF4JkR3KkO4Ejef/XjmRsFhsWw4LVsGpKLOlUFD5FRKRDeRw2+mba6JuZ0OIxpmlSVR+kuLqxed9LcZWvSVN/Yy1rjS9InT/E1tI6tpbWtfiZADaLQUZiAhkJ6WQkOshMdJKR4CAr0Ulm4+tEBxkN+112K2EzTLW/mgpfBeXe8v3WjTWuFb4K6oKRIFsfrMcb9FIfrCdkhgAIhAME/AGq/FWH/DM0MLAa1kgYtUTWjcHUYljw2Dyku9MjT8baZ0lzpZHhijw1K9WVit1iP+TyiByIwqeIiBzxDMMgxWMnxWM/YH9UgDp/cK9g6t2r6b/p67JaP8Gw2VDL6oupHElOW5MwmpnkJDOhBxmJfeiW6GBIeiS0ZiQ4SXHbsVia1kiapkkgHIgG0mg4DURqWiv9lVT5qlpcV/mrqPJVETSDTT8XM7LPBML7l7uMMnbU7IjpOyY7kkm0J0b6vNo9JNgSIv1g9+oP2/jaZXGx3r+e9IJ0Utwp0fMa15qJQJqj8CkiIl2Kx2GjT6aNPgeoSQXwB8OU1voorfGzu8bH7ho/pTU+Smv3eV3jp7TWRyBkUu0LUu0LHrRGFSJTX6UnOMhIcEQCa4KT9AQHmYkO0hMaalQTUslIzKJXioNkly2m5nPTNKM1qGEzvGcd3ue1GSIUDhEyQ9QH6yn1llLmLaOsvoxyXzll9WWUecui+yt8FYTNcCTgxlkb+9yi55rdn2BPiIRXR0I0kLqsLpxWZ2SxRdYOqwOX1dV0bXPhsDiwWWzRxW6xN79t2LFb7SQ5kvDYPOqGcIRT+BQRkW8lhy22gVOwp9l/d0NYLa3xsbu2Yd0YUGv80fcr6wPRSf9LqmOrVXVYLQ21qo3N//s3/Te+Tk9w4bEe3lrFsBmm0ldJubecmkANdcG6SL/XQF20f2ttoDbaH7Y2UEuNv4YdxTtwJDkixwVrqfXXRmtmG4+j/rAW9YCshpUkRxLJjuSm64Z+s4373DZ3NMBaDWuTkGuz2LAZNqwWazToNp6nWQ4OncKniIjIQezd7N+/28GP9wfDlNX6ozWrZQ21qWW1/mhNamnDdlmtnxpfEH8oTEGll4JKb0xlSnLaSE2wk+ZxNCx2Uhu3Exq3G95PcJDuceB2tDy/qcWwRB+hGqvI4LF5TJ06Fbs90lfUNE18Id+egBqoabLtD/nxBr2RdSiy9oV8e5bgnm1/2E8wHIwugXAgum7cjr4OBQiaQUJm6LDMZtASl9XVZBBYdL3XtsvqIkwY0zSjNdGN29E1JmEz0kcixZHSpE9uhjuDJHtSl63BVfgUERE5zBw2S/RpU7HwBkINYTQSVktq9qphjXYF2BNgQ+E9XQC2l8VereiyW8hIcJLWEFozEvYE0/TEyDotwUGqx06K206q24HLbokrBBmGgcvmwmVzkeHOiPm8Q2WaJt6Ql2p/dbR/bLW/OtqNoLG/bOM+b9BL0IyE11A4FAmzZmR778AbNIMEQgFqAjWYRK7hrfdSXH/wJ3kdCpvFFgmiDYPBGkOpx+aBODLp0IyhnNTrpLYraCsofIqIiHQwl91KTqqbnNSDdwEIh00q6gOU1/mpqPNTXtu4HVmX1wUi+/feVxvAHwrjDYQjj1KtiD2wOqwWkt12Utw2Uj0OUtz26JLktLCzwCCwahcZSW5SGmpaU912kt12rJb2q7kzDCM6bVV3T/fD/vlhM0xNoIZKX2U0yO4davfe9of80RkHDMOITodlMSxYsETfsxiWaHeHMm9ZdKkJ1BAMx/642gO5ePDFCp8iIiLSepaGgUzpCbH3PTRNk1p/iPJaP6W1fsprI839ZbV+yur8lNU0rBveq6wPUNHQb9Xf8ESr3TU+oLaZT7fyytY1zV432RUJrKkNXQJSGkLs3gE2pSGo7r2d5Ixt8FV7shiWaPN6W/MGvZR7y5sMCCutL6XUW4o3GFu3jEaju49uo1K2nsKniIhIF2cYBolOG4lO236T/rekMbBW1georAtQUe+nqj4QCaZ1kXV5rY91m/Nxp2ZS5Q1G9tcFqPZFBhxFHgoQJL8svvJaDEh220l120lpqEnd0xWg6b7IfkdDcLXhtLXcr7WzcNlc9EjsQY/EHh1dlDah8CkiIiL72TuwttQdIDLgaCtTp46NDjgCCITCe4XUSPN/YxeAxgBb5Q1Ggu0+iz8YJmwSPYcYprXam8NmIdllI9llJ8llIym6btwXed1Y25rsspHisZPsirz2OPTEqLam8CkiIiKHld1qITPRSWaiM+5zvYFQNIhWNQTYivpIP9bKFl5HwmwA04zMNBAZnOVvVdltFqNJMG3cjoZYp22fULsn3DZu2w/zNFhdjcKniIiIHDFcdisuu5Ws5NhmCmgUCpvU+IJUewNUe4NUe4NU1Qeo9u312hugqj5yTGPNa/Veta7BsEkwbEb7w7aW227dqw+rbb9+rfv2d22sYU502kj8FoRXhU8RERHp9KwWIxroWsM0Teqb1Lo27RZQ490r2O4VaBv31fiC1PlDANQHQtQHQhRWxTc4qJHDZiHJaSNhn1Da+DrJ1XR/UsN6z3t2El02PHbrfo94PRIofIqIiMi3nmEYeBw2PA5bTE+9ak4wFKbGF2wSXKu8+/drbexS0Liu8UXCqzcQmXTeHwxTGozMTHBo3wl+MKE3d5037JA+53BT+BQRERE5DGxWS8PUUq17BGcwFKbWF6LGH6SmoTa1xhek1hd5Xd247QtGa1trvIGmrxu2Q2ET0+SIbMJX+BQRERE5AtisFlI8FlI8res60Mg0TXzBMNXeIHarmt1FREREpA0ZhhEduHUkOvLqYkVERESky1L4FBEREZF2o/ApIiIiIu1G4VNERERE2o3Cp4iIiIi0G4VPEREREWk3Cp8iIiIi0m4UPkVERESk3Sh8ioiIiEi7UfgUERERkXaj8CkiIiIi7UbhU0RERETajcKniIiIiLQbhU8RERERaTcKnyIiIiLSbhQ+RURERKTdKHyKiIiISLtR+BQRERGRdqPwKSIiIiLtRuFTRERERNqNwqeIiIiItBuFTxERERFpNwqfIiIiItJuFD5FREREpN0ofIqIiIhIu1H4FBEREZF206rw+cgjj9CnTx9cLhcTJkzg008/PeDxL774IkcddRQul4vhw4czb968VhVWRERERDq3uMPnCy+8wMyZM5k9ezYrV65k5MiRTJkyheLi4maP//jjj7nkkkv40Y9+xOeff855553Heeedx5o1aw658CIiIiLSucQdPh944AGuueYarrrqKo4++mgeffRRPB4PTzzxRLPHP/TQQ5x55pn86le/YsiQIdx1112MHj2ahx9++JALLyIiIiKdiy2eg/1+PytWrGDWrFnRfRaLhcmTJ7N06dJmz1m6dCkzZ85ssm/KlCm89tprLV7H5/Ph8/mirysrKwEoKysjEAjEU+RWCQQC1NXVUVpait1ub/PrSdvRvew6dC+7Dt3LrkP3sus4HPeyuroaANM0D3hcXOFz9+7dhEIhsrKymuzPyspi3bp1zZ5TWFjY7PGFhYUtXmfOnDnceeed++3v27dvPMUVERERkXZWXV1NSkpKi+/HFT7by6xZs5rUlobDYcrKysjIyMAwjDa/flVVFbm5uWzfvp3k5OQ2v560Hd3LrkP3suvQvew6dC+7jsNxL03TpLq6mp49ex7wuLjCZ2ZmJlarlaKioib7i4qKyM7Obvac7OzsuI4HcDqdOJ3OJvtSU1PjKephkZycrD+mLkL3suvQvew6dC+7Dt3LruNQ7+WBajwbxTXgyOFwMGbMGBYuXBjdFw6HWbhwIRMnTmz2nIkTJzY5HmDBggUtHi8iIiIiXVfcze4zZ85k+vTpjB07lvHjx/Pggw9SW1vLVVddBcAVV1xBTk4Oc+bMAeAXv/gFJ598Mvfffz9nn302zz//PJ999hmPPfbY4f0mIiIiInLEizt8XnzxxZSUlHDHHXdQWFjIqFGjmD9/fnRQUX5+PhbLngrV4447jmeffZbbbruNX//61wwcOJDXXnuNYcOGHb5vcZg5nU5mz569X9O/dD66l12H7mXXoXvZdehedh3teS8N82Dj4UVEREREDhM9211ERERE2o3Cp4iIiIi0G4VPEREREWk3Cp8iIiIi0m4UPvfxyCOP0KdPH1wuFxMmTODTTz/t6CJJDD744AOmTZtGz549MQyD1157rcn7pmlyxx130KNHD9xuN5MnT2bDhg0dU1hp0Zw5cxg3bhxJSUl0796d8847j/Xr1zc5xuv1cu2115KRkUFiYiIXXnjhfg+ykI73f//3f4wYMSI6YfXEiRN56623ou/rPnZe99xzD4ZhcMMNN0T36X52Dr/97W8xDKPJctRRR0Xfb6/7qPC5lxdeeIGZM2cye/ZsVq5cyciRI5kyZQrFxcUdXTQ5iNraWkaOHMkjjzzS7Pt//OMf+ctf/sKjjz7KJ598QkJCAlOmTMHr9bZzSeVA3n//fa699lqWLVvGggULCAQCnHHGGdTW1kaPufHGG/nf//7Hiy++yPvvv8+uXbu44IILOrDU0pxevXpxzz33sGLFCj777DNOO+00zj33XL766itA97GzWr58OX//+98ZMWJEk/26n53H0KFDKSgoiC4fffRR9L12u4+mRI0fP9689tpro69DoZDZs2dPc86cOR1YKokXYL766qvR1+Fw2MzOzjbvu+++6L6KigrT6XSazz33XAeUUGJVXFxsAub7779vmmbkvtntdvPFF1+MHrN27VoTMJcuXdpRxZQYpaWlmf/4xz90Hzup6upqc+DAgeaCBQvMk08+2fzFL35hmqb+LjuT2bNnmyNHjmz2vfa8j6r5bOD3+1mxYgWTJ0+O7rNYLEyePJmlS5d2YMnkUG3ZsoXCwsIm9zYlJYUJEybo3h7hKisrAUhPTwdgxYoVBAKBJvfyqKOOIi8vT/fyCBYKhXj++eepra1l4sSJuo+d1LXXXsvZZ5/d5L6B/i47mw0bNtCzZ0/69evHZZddRn5+PtC+9zHuJxx1Vbt37yYUCkWf1NQoKyuLdevWdVCp5HAoLCwEaPbeNr4nR55wOMwNN9zA8ccfH30iWmFhIQ6Hg9TU1CbH6l4emb788ksmTpyI1+slMTGRV199laOPPppVq1bpPnYyzz//PCtXrmT58uX7vae/y85jwoQJPPXUUwwePJiCggLuvPNOTjzxRNasWdOu91HhU0SOSNdeey1r1qxp0h9JOpfBgwezatUqKisreemll5g+fTrvv/9+RxdL4rR9+3Z+8YtfsGDBAlwuV0cXRw7BWWedFd0eMWIEEyZMoHfv3vz3v//F7Xa3WznU7N4gMzMTq9W636iuoqIisrOzO6hUcjg03j/d285jxowZvPnmmyxatIhevXpF92dnZ+P3+6moqGhyvO7lkcnhcDBgwADGjBnDnDlzGDlyJA899JDuYyezYsUKiouLGT16NDabDZvNxvvvv89f/vIXbDYbWVlZup+dVGpqKoMGDWLjxo3t+nep8NnA4XAwZswYFi5cGN0XDodZuHAhEydO7MCSyaHq27cv2dnZTe5tVVUVn3zyie7tEcY0TWbMmMGrr77Ke++9R9++fZu8P2bMGOx2e5N7uX79evLz83UvO4FwOIzP59N97GQmTZrEl19+yapVq6LL2LFjueyyy6Lbup+dU01NDZs2baJHjx7t+nepZve9zJw5k+nTpzN27FjGjx/Pgw8+SG1tLVdddVVHF00Ooqamho0bN0Zfb9myhVWrVpGenk5eXh433HADv//97xk4cCB9+/bl9ttvp2fPnpx33nkdV2jZz7XXXsuzzz7L66+/TlJSUrSfUUpKCm63m5SUFH70ox8xc+ZM0tPTSU5O5rrrrmPixIkce+yxHVx62dusWbM466yzyMvLo7q6mmeffZbFixfz9ttv6z52MklJSdF+140SEhLIyMiI7tf97Bxuuukmpk2bRu/evdm1axezZ8/GarVyySWXtO/f5WEdO98F/PWvfzXz8vJMh8Nhjh8/3ly2bFlHF0lisGjRIhPYb5k+fbppmpHplm6//XYzKyvLdDqd5qRJk8z169d3bKFlP83dQ8B88skno8fU19ebP//5z820tDTT4/GY559/vllQUNBxhZZm/fCHPzR79+5tOhwOs1u3buakSZPMd955J/q+7mPntvdUS6ap+9lZXHzxxWaPHj1Mh8Nh5uTkmBdffLG5cePG6PvtdR8N0zTNwxtnRURERESapz6fIiIiItJuFD5FREREpN0ofIqIiIhIu1H4FBEREZF2o/ApIiIiIu1G4VNERERE2o3Cp4iIiIi0G4VPEREREWk3Cp8iIiIi0m4UPkVERESk3Sh8ioiIiEi7UfgUERERkXbz/8GCEittaQrIAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0941 - accuracy: 0.9706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09410056471824646, 0.9706000089645386]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miguel Angel\\AppData\\Local\\Temp\\ipykernel_9260\\1468152043.py:2: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.32941177, 0.7254902 , 0.62352943, 0.5921569 ,\n",
       "         0.23529412, 0.14117648, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.87058824, 0.99607843, 0.99607843, 0.99607843,\n",
       "         0.99607843, 0.94509804, 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.6666667 , 0.20392157, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.2627451 , 0.44705883, 0.28235295, 0.44705883,\n",
       "         0.6392157 , 0.8901961 , 0.99607843, 0.88235295, 0.99607843,\n",
       "         0.99607843, 0.99607843, 0.98039216, 0.8980392 , 0.99607843,\n",
       "         0.99607843, 0.54901963, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "         0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "         0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.3254902 , 0.99215686,\n",
       "         0.81960785, 0.07058824, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.08627451, 0.9137255 , 1.        ,\n",
       "         0.3254902 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5058824 , 0.99607843, 0.93333334,\n",
       "         0.17254902, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.23137255, 0.9764706 , 0.99607843, 0.24313726,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.03529412, 0.8039216 , 0.972549  , 0.22745098, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.49411765, 0.99607843, 0.7137255 , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.29411766,\n",
       "         0.9843137 , 0.9411765 , 0.22352941, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.07450981, 0.8666667 ,\n",
       "         0.99607843, 0.6509804 , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "         0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.14901961, 0.99607843, 0.99607843,\n",
       "         0.3019608 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.12156863, 0.8784314 , 0.99607843, 0.4509804 ,\n",
       "         0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.23921569, 0.9490196 , 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.8117647 , 0.07058824, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 634ms/step\n",
      "(1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.2715409e-06, 1.2016974e-07, 9.8660246e-05, 3.6083968e-04,\n",
       "        4.6809410e-09, 1.8779674e-07, 9.8664991e-12, 9.9952412e-01,\n",
       "        1.0608882e-06, 1.3704642e-05]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:1])\n",
    "print(predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miguel Angel\\AppData\\Local\\Temp\\ipykernel_9260\\1084033691.py:1: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_test[2].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[2].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 961,    0,    3,    1,    1,    2,    4,    1,    2,    5],\n",
       "       [   0, 1126,    2,    1,    0,    1,    2,    1,    2,    0],\n",
       "       [   4,    3, 1003,    5,    3,    0,    2,    7,    5,    0],\n",
       "       [   0,    0,    2,  982,    0,    8,    0,    8,    3,    7],\n",
       "       [   0,    0,    3,    0,  957,    0,    3,    2,    2,   15],\n",
       "       [   3,    1,    0,    8,    1,  855,    8,    1,    7,    8],\n",
       "       [   5,    3,    0,    0,    4,    6,  937,    0,    3,    0],\n",
       "       [   0,   10,    7,    2,    0,    0,    0,  989,    1,   19],\n",
       "       [   3,    1,    5,    9,    5,    5,    9,    5,  919,   13],\n",
       "       [   3,    6,    0,    4,   11,    2,    1,    5,    0,  977]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, model.predict(X_test).argmax(axis=1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362.8125"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11610/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.0174 - val_loss: 0.6557\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5346 - val_loss: 0.4945\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4694 - val_loss: 0.4610\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4538 - val_loss: 0.4615\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4446 - val_loss: 0.4420\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4348 - val_loss: 0.4331\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4356 - val_loss: 0.4351\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4258 - val_loss: 0.4283\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4186 - val_loss: 0.4215\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4138 - val_loss: 0.4144\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4101 - val_loss: 0.4120\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4332 - val_loss: 0.4452\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4142 - val_loss: 0.4102\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4079 - val_loss: 0.4078\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3990 - val_loss: 0.4045\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3955 - val_loss: 0.4008\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3894 - val_loss: 0.3913\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3918 - val_loss: 0.4059\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3894 - val_loss: 0.3893\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3848 - val_loss: 0.3873\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = 'relu',\n",
    "                      input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = \"mean_squared_error\",\n",
    "             optimizer = \"sgd\")\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs = 20,\n",
    "                   validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*30 + 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 30)                270       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301 (1.18 KB)\n",
      "Trainable params: 301 (1.18 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3745\n",
      "0.3745432198047638\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 119ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.4855702],\n",
       "       [2.669297 ],\n",
       "       [2.4974709],\n",
       "       [2.906237 ],\n",
       "       [1.8799869]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test[:5])\n",
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model(\"my_keras_model.keras\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Son funciones predefinidas de Keras a aplicar durante el entrenamiento\n",
    "Por ejemplo, `ModelCheckpoint` sirve para que el modelo se vaya guardando tras cada epoch. Así no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3905\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3777\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3793\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3779\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3943\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3729\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3743\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3690\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3783\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3809\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4003\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3817\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3701\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3670\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3625\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3621\n",
      "Epoch 17/30\n",
      " 19/363 [>.............................] - ETA: 0s - loss: 0.3561"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9260\\3275254796.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcheckpoint_cb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"callback_model.keras\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m history = model.fit(X_train,\n\u001b[0m\u001b[0;32m      3\u001b[0m                    \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                    \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                    callbacks = [checkpoint_cb])\n",
      "\u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1794\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1795\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1796\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1797\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1798\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1799\u001b[0m                         with tf.profiler.experimental.Trace(\n\u001b[0;32m   1800\u001b[0m                             \u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1801\u001b[0m                             \u001b[0mepoch_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1407\u001b[0m             \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_current_step\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inferred_steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1408\u001b[0m         ):\n\u001b[0;32m   1409\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1410\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1411\u001b[1;33m             \u001b[0moriginal_spe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1412\u001b[0m             can_run_full_execution = (\n\u001b[0;32m   1413\u001b[0m                 \u001b[0moriginal_spe\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1414\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inferred_steps\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    687\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    690\u001b[0m     raise NotImplementedError(\n\u001b[0;32m    691\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    838\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Read\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m       \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m     \u001b[1;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m     \u001b[1;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 842\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[0mbound_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbound_arguments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1258\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1260\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1261\u001b[1;33m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1262\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1263\u001b[0m         \u001b[1;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1264\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m    308\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"graph\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;31m# Make sure we get an input with handle data attached from resource\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m   \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m   \u001b[1;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_handle_data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_data\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m   4185\u001b[0m         _ctx, \"Identity\", name, input)\n\u001b[0;32m   4186\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4187\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4188\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4189\u001b[1;33m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4190\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4191\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4192\u001b[0m       return identity_eager_fallback(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"callback_model.keras\")\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=30,\n",
    "                   callbacks = [checkpoint_cb])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3584 - val_loss: 0.3679\n",
      "Epoch 2/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3576 - val_loss: 0.3651\n",
      "Epoch 3/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3551 - val_loss: 0.3664\n",
      "Epoch 4/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3533 - val_loss: 0.3654\n",
      "Epoch 5/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3561 - val_loss: 0.3776\n",
      "Epoch 6/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3524 - val_loss: 0.3618\n",
      "Epoch 7/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3514 - val_loss: 0.3579\n",
      "Epoch 8/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3502 - val_loss: 0.3556\n",
      "Epoch 9/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3488 - val_loss: 0.3585\n",
      "Epoch 10/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3486 - val_loss: 0.3571\n",
      "Epoch 11/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3489 - val_loss: 0.3637\n",
      "Epoch 12/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3479 - val_loss: 0.3613\n",
      "Epoch 13/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3471 - val_loss: 0.3518\n",
      "Epoch 14/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3453 - val_loss: 0.3569\n",
      "Epoch 15/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3441 - val_loss: 0.3523\n",
      "Epoch 16/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3441 - val_loss: 0.3523\n",
      "Epoch 17/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3418 - val_loss: 0.3498\n",
      "Epoch 18/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3447 - val_loss: 0.3569\n",
      "Epoch 19/50\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3417 - val_loss: 0.3481\n",
      "Epoch 20/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3419 - val_loss: 0.3590\n",
      "Epoch 21/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3406 - val_loss: 0.3492\n",
      "Epoch 22/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3426 - val_loss: 0.3619\n",
      "Epoch 23/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3409 - val_loss: 0.3495\n",
      "Epoch 24/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3392 - val_loss: 0.3441\n",
      "Epoch 25/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3366 - val_loss: 0.3441\n",
      "Epoch 26/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3358 - val_loss: 0.3466\n",
      "Epoch 27/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3351 - val_loss: 0.3448\n",
      "Epoch 28/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3344 - val_loss: 0.3436\n",
      "Epoch 29/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3346 - val_loss: 0.3392\n",
      "Epoch 30/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3322 - val_loss: 0.3409\n",
      "Epoch 31/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3327 - val_loss: 0.3509\n",
      "Epoch 32/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3310 - val_loss: 0.3385\n",
      "Epoch 33/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3304 - val_loss: 0.3864\n",
      "Epoch 34/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3347 - val_loss: 0.3372\n",
      "Epoch 35/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3579 - val_loss: 0.3450\n",
      "Epoch 36/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3325 - val_loss: 0.3380\n",
      "Epoch 37/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3278 - val_loss: 0.3339\n",
      "Epoch 38/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3273 - val_loss: 0.3337\n",
      "Epoch 39/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3257 - val_loss: 0.3329\n",
      "Epoch 40/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3261 - val_loss: 0.3335\n",
      "Epoch 41/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3241 - val_loss: 0.3294\n",
      "Epoch 42/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3233 - val_loss: 0.3362\n",
      "Epoch 43/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3232 - val_loss: 0.3335\n",
      "Epoch 44/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3259 - val_loss: 0.3339\n",
      "Epoch 45/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3218 - val_loss: 0.3281\n",
      "Epoch 46/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3355 - val_loss: 0.3339\n",
      "Epoch 47/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3259 - val_loss: 0.3316\n",
      "Epoch 48/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3227 - val_loss: 0.3255\n",
      "Epoch 49/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3208 - val_loss: 0.3255\n",
      "Epoch 50/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3215 - val_loss: 0.3911\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5)\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=50,\n",
    "                   validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [early_stopping_cb, checkpoint_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "90139cb9a825bf3d63f6f6704e828dbd1ff7edbd4d0c6e906a71235d6efc74af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
